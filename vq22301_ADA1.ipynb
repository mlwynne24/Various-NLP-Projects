{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba36903-ee71-4a62-9bb8-8e0270fdae64",
   "metadata": {},
   "source": [
    "# Advanced Text Analytics Lab 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de31fe1-70a5-4357-b9d9-be40038c556c",
   "metadata": {},
   "source": [
    "This notebook is the first of two lab notebooks that you will submit as part of your assessment for the Advanced Data Analytics unit. \n",
    "\n",
    "This notebook is contains three sections:\n",
    "1. **Word embeddings:** This will introduce you to loading and training word embeddings using the Gensim library.\n",
    "2. **Introducing neural text classifiers:** Here we show you how to construct a neural network text classifier for sentiment analysis using Pytorch. \n",
    "3. **Improving neural text classifiers:** This section gives you a chance to improve the classifier from the previous section by applying what we have learned in the lectures.\n",
    "\n",
    "## Learning Outcomes\n",
    "\n",
    "These sections will contain tutorial-like instructions, as you have seen in previous text analytics labs. On completing these sections, the intended learning outcomes are that you will be able to...\n",
    "1. Load pretrained word embeddings models.\n",
    "1. Learn word embeddings from an unlabelled dataset.\n",
    "1. Recognise the steps required to train and test a neural text classifier with Pytorch\n",
    "1. Adapt the architecture of a neural text classifier.\n",
    "\n",
    "## Getting Started -- Python Packages\n",
    "\n",
    "Please see the README.md file for instructions on setting up your Python environment. The readme will instruct you to install the required packages, in addition to those used for Introduction to Data Analytics:\n",
    "\n",
    " * pytorch=1.9.0\n",
    " * scipy=1.8.0\n",
    " * transformers=2.1.1\n",
    "\n",
    "## Your Tasks\n",
    "\n",
    "Inside each of these sections there are several **'To-do's**, which you must complete for your summative assessment. Your marks will be based on your answers to these to-dos. Please make sure to:\n",
    "1. Include the output of your code in the saved notebook. Plots and printed output should be visible without re-running the code. \n",
    "1. Include all code needed to generate your answers.\n",
    "1. Provide sufficient comments to understand how your method works.\n",
    "1. Write text in a cell in markdown format where a written answer is required. You can convert a cell to markdown format by pressing Escape-M. \n",
    "\n",
    "There are also some unmarked 'to-do's that are part of the tutorial to help you learn how to implement and use the methods studied here. These do not contribute to your final marks.\n",
    "\n",
    "## Good Academic Practice\n",
    "\n",
    "Please follow [the guidance on academic integrity provided by the university](http://www.bristol.ac.uk/students/support/academic-advice/academic-integrity/).\n",
    "You are required to write your own answers -- do not share your notebooks or copy someone else's writing. Do not copy text or long blocks of code directly into the notebook from online sources -- always rewrite in your own way. Breaking the rules can lead to strong penalties. \n",
    "\n",
    "## Marking Criteria\n",
    "\n",
    "1. The coursework (both notebooks) is worth 30% of the unit in total. \n",
    "1. There is a total of 100 marks available for both lab notebooks. \n",
    "1. This notebook is worth 50 of those marks.\n",
    "1. The number of marks for each to-do out of 100 is shown alongside each to-do.\n",
    "1. For to-dos that require you to write code, a good solution would meet the following criteria (in order of importance):\n",
    "   1. Solves the task or answers the question asked in the to-do. This means, if the code cells in the notebook are executed in order, we will get the output shown in your notebook.\n",
    "   1. The code is easy to follow and does not contain unnecessary steps.\n",
    "   1. The comments show that you understand how your solution works.\n",
    "   1. A very good answer will also provide code that is computationally efficient but easy to read.\n",
    "1. You can use any suitable publicly available libraries. Unless the task explicitly asks you to implement something from scratch, there is no penalty for using libraries to implement some steps.\n",
    "\n",
    "## Support\n",
    "\n",
    "The main source of support will be during the remaining lab sessions (Fridays 3-6pm) for this unit. \n",
    "\n",
    "The TAs and lecturer will help you with questions about the lectures, the code provided for you in this notebook, and general questions about the topics we cover. For the marked 'to-dos', they can only answer clarifying questions about what you have to do. \n",
    "\n",
    "Office hours: You can book office hours with Edwin on Mondays 3pm-5pm by sending him an email (edwin.simpson@bristol.ac.uk). If those times are not possible for you, please contact him by email to request an alternative. \n",
    "\n",
    "## Deadline\n",
    "\n",
    "The notebook must be submitted along with the second notebook on Blackboard before **Wednesday 24th May at 13.00**. \n",
    "\n",
    "## Submission\n",
    "\n",
    "You will need to zip up this notebook and the next notebook into a single .zip file, which you will submit to Blackboard through the 'assessment, submission and feedback' link on the left sidebar. \n",
    "\n",
    "Please name your files like this:\n",
    "   * Name this notebook ADA1_<student_number>.ipynb\n",
    "   * Name the zip file <student_number>.zip\n",
    "   * Please don't include your name as we want to mark anonymously to ensure fairness. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c549d0b9-84d1-4d35-80b1-6341a3ea7ce6",
   "metadata": {},
   "source": [
    "# 1. Word Embeddings (max. 12 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1a8852-b72a-48dd-a266-25a4bb774f6a",
   "metadata": {},
   "source": [
    "In this section we will use both sparse vectors and dense word2vec embeddings to obtain\n",
    "vector representations of words and documents. \n",
    "\n",
    "First, we will load the `tweet eval` sentiment dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5519c4b9-1cac-4e8a-9e7e-a8a40b389bdf",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e599bf09-ed1a-4e40-a551-2e3a889a3487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset tweet_eval (C:/Users/Morg/OneDrive/Documents/MSc/TB2/advanced_data_analytics/text_analytics/advanced-labs-public/data_cache/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 45615 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset tweet_eval (C:/Users/Morg/OneDrive/Documents/MSc/TB2/advanced_data_analytics/text_analytics/advanced-labs-public/data_cache/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development/validation dataset with 2000 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset tweet_eval (C:/Users/Morg/OneDrive/Documents/MSc/TB2/advanced_data_analytics/text_analytics/advanced-labs-public/data_cache/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 12284 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 45615/45615 [00:16<00:00, 2839.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary has 43358 words\n",
      "Index of \"love\" is 22981\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"sentiment\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "\n",
    "print(f\"Training dataset with {len(train_dataset)} instances loaded\")\n",
    "\n",
    "\n",
    "dev_dataset = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"sentiment\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "\n",
    "print(f\"Development/validation dataset with {len(dev_dataset)} instances loaded\")\n",
    "\n",
    "\n",
    "test_dataset = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"sentiment\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "\n",
    "print(f\"Test dataset with {len(test_dataset)} instances loaded\")\n",
    "\n",
    "# Put the data into lists ready for the next steps...\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "for i in tqdm(range(len(train_dataset))):\n",
    "    train_texts.append(train_dataset[i]['text'])\n",
    "    train_labels.append(train_dataset[i]['label'])\n",
    "            \n",
    "# HINT: A count vectorizer object may be useful in later steps\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_texts)\n",
    "\n",
    "# Get the vocabulary\n",
    "vocab = vectorizer.vocabulary_\n",
    "vocab_size = len(vocab)\n",
    "print(f'The vocabulary has {vocab_size} words')\n",
    "\n",
    "# invert the vocabulary dictionary so we can look up word types given an index\n",
    "keys = vocab.values()\n",
    "values = vocab.keys()\n",
    "vocab_inverted = dict(zip(keys, values))\n",
    "\n",
    "print(f'Index of \"love\" is {vocab[\"love\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a63c3c-d24c-4810-9c34-4532b845e310",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1. Term-Document Matrix\n",
    "\n",
    "First we are going to obtain sparse word vectors from a term-document matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd30abb-0951-46ee-81a6-b9217fba6b90",
   "metadata": {},
   "source": [
    "**TO-DO 1a:** Use CountVectorizer to obtain a term-document matrix for the training set. Then, write a function that takes a word as an argument and returns its term vector from the term-document matrix you computed. Get the term vector for the word 'love'. **(4 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52a52da7-89a5-41d6-bfab-83b3231d6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.transform(train_texts)\n",
    "\n",
    "def get_term_vec(td_matrix, word):\n",
    "    idx = vocab[word]  # gets index of the word in the vocabulary\n",
    "    return td_matrix.T[idx]  # use transpose to get the word vector for the corresponding index\n",
    "\n",
    "love_vec = get_term_vec(X, 'love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a286c6e1-f3e9-4c40-b968-0c24eb8dbaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of words for comparison with 'love' in the next to-do.\n",
    "comparison_words = ['2wee', '4your', 'follow', 'goodnight', 'liam', 'lol', 'okay', 'sorry',\n",
    " 'wish', 'yea', 'affair', 'agree', 'all', 'alliums', 'alliumsvancouver', 'always',\n",
    " 'amazing', 'and', 'appreciate', 'ask', 'babe', 'baby', 'bandit76044', 'barat',\n",
    " 'beautiful', 'birthday', 'boy', 'bro', 'btw', 'but', 'commando', 'content',\n",
    " 'dear', 'dm', 'dream', 'dreams', 'enjoy', 'enjoyed', 'everything', 'fam',\n",
    " 'followers', 'for', 'forever', 'forget', 'friend', 'friends', 'gabrielle',\n",
    " 'girl', 'god', 'good', 'guys', 'hahaha', 'happy', 'hate', 'hello', 'hey',\n",
    " 'homework', 'hope', 'in', 'invite', 'is', 'isabel', 'it', 'jonny', 'kiss', 'know',\n",
    " 'krishna', 'ladies', 'let', 'life', 'like', 'lil', 'little', 'love', 'loved',\n",
    " 'loves', 'loving', 'lucky', 'luv', 'ma', 'may', 'me', 'mean', 'meet', 'met', 'miss',\n",
    " 'much', 'my', 'notice', 'nsfanfic', 'nuffsaid', 'nya', 'of', 'on', 'one',\n",
    " 'ontario', 'perfect', 'prefer', 'queen', 'rails', 'rather', 'recommend',\n",
    " 'remember', 'see', 'share', 'sing', 'smile', 'so', 'suggest', 'sunat', 'sweet',\n",
    " 'tag', 'tail', 'tebaklagu', 'thank', 'thanks', 'the', 'this', 'thsoul', 'to',\n",
    " 'tomorrow', 'too', 'true', 'unreservedly', 'user', 'want', 'weed', 'what', 'wish',\n",
    " 'wishes', 'with', 'women_of_christ', 'would', 'wow', 'xxxxxx', 'yay', 'yes',\n",
    " 'you', 'your', 'zorro',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb324d8-a92a-4fd7-bd7f-f3b0f0958e6b",
   "metadata": {},
   "source": [
    "**TO-DO 1b:** Write a function that computes the similarity between two different term vectors. For this to-do, do not simply call a library function that implements a similarity function, implement the calculation yourself. Use the function to find the five most similar terms to \"love\" from the list of `comparison_words` given above. **(6 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a2cca67-685e-4760-92be-eea50ed87769",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['love', 'you', 'user', 'the', 'and'], dtype='<U16')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cos_sim(a, b):\n",
    "    dot_p = np.dot(a.toarray(), b.T.toarray())  # dot product of both word vectors\n",
    "    norm_mult = np.linalg.norm(a.toarray()) * np.linalg.norm(b.toarray())  # multiply the norm of each word vector\n",
    "    return dot_p[0][0] / norm_mult  # returns cosine similarity\n",
    "\n",
    "word_sims = []\n",
    "\n",
    "for word in comparison_words:\n",
    "    term_vec = get_term_vec(X, word)  # gets vector for corresponding term\n",
    "    word_sims.append(cos_sim(love_vec, term_vec))  # appends cos sims of each term and 'love' to a list\n",
    "    \n",
    "np.array(comparison_words)[(np.argsort(np.array(word_sims)))][::-1][0:5]  # returns an array of the top most similar comparison words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9654fde-cbe7-4020-99f7-49d97b4eacfa",
   "metadata": {},
   "source": [
    "## 1.2 Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e772ce7-853e-478d-9d0a-3f591100e88d",
   "metadata": {},
   "source": [
    "Now, we will use Gensim to train a word2vec model. The code below tokenizes the training texts, then runs word2vec (the skipgram model) to learn a set of embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b5d13e1-683f-41f6-bf24-7c036aef59fa",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from gensim.utils import tokenize\n",
    "\n",
    "tokenized_texts = [list(tokenize(text)) for text in train_texts]\n",
    "emb_model = word2vec.Word2Vec(tokenized_texts, sg=1, min_count=1, window=3, vector_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "989624ac-dc98-461f-a5ad-c28cf27ca085",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the word vector for 'love'\n",
    "love_embedding = emb_model.wv['love']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd66ea-cbbe-4c1a-a467-5a784facf33b",
   "metadata": {},
   "source": [
    "**TODO 1c:** Find the five most similar words to 'love' according to your word2vec model. You can use the Gensim function `similar_by_word` to do this. How does the Word2Vec top 5 differ from the top 5 comparison words found using the term-document matrix? **(2 marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd540aa",
   "metadata": {},
   "source": [
    "**ANSWER:** The Word2Vec words are semantically similar to 'love'. Whereas, the comparison words found using the term-document matrix are words that co-occur frequently with 'love' syntactically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc37a093-db74-4e10-9224-0740381b30fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('appreciate', 0.8474551439285278),\n",
       " ('Wish', 0.8440349102020264),\n",
       " ('god', 0.8343996405601501),\n",
       " ('dear', 0.8342585563659668),\n",
       " ('recommend', 0.830489993095398),\n",
       " ('loving', 0.8299885392189026)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.wv.similar_by_word('love', topn=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb28de29-ee93-47e9-ba62-de7771d7203d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Above, we trained our own model using the skipgram method. We can also download a pretrained model that has previously been trained on a large corpus. There is a list of models available [here](https://radimrehurek.com/gensim/models/word2vec.html#pretrained-models). Let's try out GLoVe embeddings. GLoVe is an alternative to the skipgram model. This model was trained on a corpus of tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "693126a6-519a-44c1-b800-773fc95d38df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.62645  -0.082389  0.070538  0.5782   -0.87199  -0.14816   2.2315\n",
      "  0.98573  -1.3154   -0.34921  -0.8847    0.14585  -4.97     -0.73369\n",
      " -0.94359   0.035859 -0.026733 -0.77538  -0.30014   0.48853  -0.16678\n",
      " -0.016651 -0.53164   0.64236  -0.10922 ]\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "glove_wv = gensim.downloader.load('glove-twitter-25')\n",
    "\n",
    "# show the vector for Hamlet:\n",
    "print(glove_wv['love'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcbeb21-549d-4315-bce1-e785cda13fd2",
   "metadata": {},
   "source": [
    "TODO 1d: Find the most similar five words to 'happy' according to the GloVe Twitter model. (this task is unmarked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc39168a-7b01-4171-beb2-8a4bf035fd71",
   "metadata": {},
   "source": [
    "Notice again that a different set of words are favoured than with word2vec or term-document vectors, and consider how this might result from pretraining the embeddings on Twitter data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421d24e4-d90d-4f50-a167-5f4876076355",
   "metadata": {},
   "source": [
    "# 2. Introducing Neural Text Classifiers (max. 16 marks)\n",
    "\n",
    "This section shows you how to implement a neural network classifier using Pytorch and leads you through the steps required to process text sequences.\n",
    "\n",
    "There are several big advantages to building a text classifier using a neural network:\n",
    "   * It can model nonlinear functions, so can handle much more complex relationships between features and class labels.\n",
    "   * It performs representation learning: the hidden layers learn how to extract features from low-level data.\n",
    "   * It can process sequences of tokens -- we don't have to think in terms of a single feature vector representing a document as we did for logistic regression.\n",
    "  \n",
    "The downsides are:\n",
    "   * Much more expensive to train and test.\n",
    "   * It can overfit very badly to small datasets.\n",
    "   * The features learned by the hidden layers can be hard to interpret, which can make it hard to predict the model's behaviour, e.g., what sort of cases it may fail on.\n",
    "   \n",
    "Let's start by building a neural network text classifier that takes a sequence of tokens as input, and predicts a class label. For simplicity, it will use a single fully connected feedforward layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca4f88e-bd86-4917-8e9d-26ace635873e",
   "metadata": {},
   "source": [
    "\n",
    "We are going to construct the neural network in this form:\n",
    "\n",
    "<img src=\"neural_text_classifier_smaller.png\" alt=\"Neural text classifier diagram\" width=\"600px\"/>\n",
    "\n",
    "The first step -- as always -- is to get our data into the right format. We start from a set of tokenised documents (in this case, tweets), where each document is represented as a sequence of text tokens. The neural network cannot process the tokens as strings, so we need to convert each token to a numerical input value. The input value for each token is used to look up the corresponding embedding in the embedding layer. For PyTorch, it's not necessary to create one-hot vectors for each token, as library just uses the indexes of the words in the vocabulary to look up the corresponding word embedding. \n",
    "\n",
    "So, let's now map the tokens to their IDs -- their indexes in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42a71101-e504-42a8-9862-74796af52cd0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Morg\\OneDrive\\Documents\\MSc\\TB2\\advanced_data_analytics\\text_analytics\\advanced-labs-public\\data_cache\\tweet_eval\\sentiment\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343\\cache-9d9026ae5ba62cd4.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45615"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize training set and convert to input IDs.\n",
    "def encode_text(sample):\n",
    "    tokens = tokenize(sample['text'])  # Tokenize one document\n",
    "    \n",
    "    input_ids = []\n",
    "    for token in tokens:\n",
    "        if str.lower(token) in vocab:  # Skip words from the dev/test set that are not in the vocabulary.\n",
    "            input_ids.append(vocab[str.lower(token)]+1) # +1 is needed because we reserve 0 as a special character\n",
    "            \n",
    "    sample['input_ids'] = input_ids \n",
    "    return sample\n",
    "\n",
    "# The map method of the dataset object takes a function as its argument, \n",
    "# and applies that function to each document in the dataset.\n",
    "train_dataset = train_dataset.map(encode_text)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ce8d8c-ce83-49b7-9b88-b84233be7dbf",
   "metadata": {},
   "source": [
    "Our neural network's input layer has a fixed size, so we need to make all of our documents have the same number of tokens. Let's plot a histogram to understand the length distribution of the texts in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "832da949-3fec-4d26-936e-23c943546b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the document length: 18.160166611860134\n",
      "Median of the document length: 18.0\n",
      "Maximum document length: 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([   21.,   522.,  2430.,  4908.,  7772., 11003., 10389.,  6738.,\n",
       "         1719.,   113.]),\n",
       " array([ 1. ,  4.1,  7.2, 10.3, 13.4, 16.5, 19.6, 22.7, 25.8, 28.9, 32. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rv_l = [len(doc) for doc in train_dataset['input_ids']]\n",
    "print('Mean of the document length: {}'.format(np.mean(rv_l)))\n",
    "print('Median of the document length: {}'.format(np.median(rv_l)))\n",
    "print('Maximum document length: {}'.format(np.max(rv_l)))\n",
    "\n",
    "plt.hist(rv_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97d92c-7002-4b63-9011-8ed21ea52e95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now neeed to choose a fixed sequence length, then *pad* the documents that are shorter than this maximum by adding a special token to the start of the sequence. The special pad token has an input value of 0. Any documents that exceed the length will be truncated.\n",
    "\n",
    "**TO-DO 2a:** Complete the padding code below to insert 0s at the start of any sequences that are too short, and to truncate any sequences that are too long. **(3 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8488dfa-61b8-438e-92ee-7f9b84b27a68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Morg\\OneDrive\\Documents\\MSc\\TB2\\advanced_data_analytics\\text_analytics\\advanced-labs-public\\data_cache\\tweet_eval\\sentiment\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343\\cache-f80f072fb6f69fdb.arrow\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 40  # truncate all docs longer than this. Pad all docs shorter than this.\n",
    "\n",
    "def pad_text(sample):\n",
    "    if len(sample['input_ids']) < 40:\n",
    "        padded_list = [0 for i in range(sequence_length - len(sample['input_ids']))]  # add (40 - number of tokens in the sample) zeros to the start of the list\n",
    "        for idx in sample['input_ids']:\n",
    "            padded_list.append(idx)  # add the tokens in the sample to the end of the list for a total length of 40\n",
    "        sample['input_ids'] = padded_list\n",
    "    else:\n",
    "        sample['input_ids'] = sample['input_ids'][0:40]  # truncate texts that are longer than 40 tokens\n",
    "    return sample\n",
    "\n",
    "# The map method will call pad_text for every document in the dataset\n",
    "train_dataset = train_dataset.map(pad_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb33a1-ca74-4a95-bbd5-2b9e50167733",
   "metadata": {},
   "source": [
    "We now have our data in almost the right format! To train a model using PyTorch, we are going to wrap our dataset in a [DataLoader object](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). This allows the training process to select random subsets of the dataset -- mini-batches -- which it will use for learning with mini-batch stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ab3c226-402b-4eb5-8f9a-fe216b4c5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# convert from the Huggingface format to a TensorDataset so we can use the mini-batch sampling functionality\n",
    "def convert_to_data_loader(dataset, num_classes):\n",
    "    # convert from list to tensor\n",
    "    input_tensor = torch.from_numpy(np.array(dataset['input_ids']))\n",
    "    label_tensor = torch.from_numpy(np.array(dataset['label'])).long()\n",
    "    tensor_dataset = TensorDataset(input_tensor, label_tensor)\n",
    "    loader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "num_classes = len(np.unique(train_labels))   # number of possible labels in the sentiment analysis task\n",
    "\n",
    "train_loader = convert_to_data_loader(train_dataset, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5825c-4a0e-4fc8-9de6-504bc7227377",
   "metadata": {},
   "source": [
    "Let's process the development and test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78aa6ddc-b936-431c-865e-dc55eaf3086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Morg\\OneDrive\\Documents\\MSc\\TB2\\advanced_data_analytics\\text_analytics\\advanced-labs-public\\data_cache\\tweet_eval\\sentiment\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343\\cache-05659c67a7f822c7.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Morg\\OneDrive\\Documents\\MSc\\TB2\\advanced_data_analytics\\text_analytics\\advanced-labs-public\\data_cache\\tweet_eval\\sentiment\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343\\cache-a47e698502cb2ccb.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Morg\\OneDrive\\Documents\\MSc\\TB2\\advanced_data_analytics\\text_analytics\\advanced-labs-public\\data_cache\\tweet_eval\\sentiment\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343\\cache-845be0dc551ecfa5.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Morg\\OneDrive\\Documents\\MSc\\TB2\\advanced_data_analytics\\text_analytics\\advanced-labs-public\\data_cache\\tweet_eval\\sentiment\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343\\cache-01a6e26e699d58c2.arrow\n"
     ]
    }
   ],
   "source": [
    "dev_dataset = dev_dataset.map(encode_text)\n",
    "dev_dataset = dev_dataset.map(pad_text)\n",
    "dev_loader = convert_to_data_loader(dev_dataset, num_classes)\n",
    "\n",
    "test_dataset = test_dataset.map(encode_text)\n",
    "test_dataset = test_dataset.map(pad_text)\n",
    "test_loader = convert_to_data_loader(test_dataset, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7b857f-5d57-44fd-a1b4-e1b31a009c72",
   "metadata": {},
   "source": [
    "As shown in the diagram above, we will build a NN with three different layers for sentiment classification.\n",
    "\n",
    "### Embedding layer\n",
    "In the embedding layer, the network will create its own embeddings for the index with a given embedding dimension.\n",
    "The module `nn.Embedding()` creates a simple lookup table that stores embeddings of a fixed dictionary and size.\n",
    "This module is often used to store word embeddings and retrieve them using indices.\n",
    "The module's input is a list of indices, and the output is the corresponding word embeddings.\n",
    "\n",
    "[Documentation for Embedding Class](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
    "\n",
    "### Fully-connected layer\n",
    "Fully-connected layers in a neural network are those layers where all the inputs from the previous layer are connected to every unit of the fully-connected layer. Here we will use fully-connected layers for the hidden layer and output layer. In Pytorch this kind of layer is implemented by the 'Linear' class:\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "\n",
    "## Activation functions\n",
    "In Pytorch, the activation function is not included in the Linear class (or other kinds of neural network layer), so we need to explicitly connect each layer to an activation function.\n",
    "In Pytorch, we construct a neural network by connecting up the output of each component to the input of the next, thereby creating a computation graph.\n",
    "To complete the hidden layer, we connect the ouput of the linear layer to a ReLU activation function, thereby creating a nonlinear function.\n",
    "\n",
    "The cell below defines a class for our neural text classifier. The constructor creates each of the layers and the activations. The dimensions of each layer need to be correct so that the output of one layer can be passed as input to the next, but the code is not yet complete.\n",
    "\n",
    "Below the constructor is the forward method. This is called in the 'forward pass' to map the neural network's inputs to its outputs. In PyTorch, we pass data through each layer of the model, connecting them together, then returning the output of the final layer.\n",
    "\n",
    "**TO-DO 2b** Complete the constructor and the forward method below for a NN with three layers. The places where you need to add code are marked in the cell below. Refer to the Pytorch documentation for additional help.  **(2 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e38a13cf-4b4d-4ac2-868c-8ad5c1b72b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FFTextClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, sequence_length, embedding_size, hidden_size, num_classes):\n",
    "        super(FFTextClassifier, self).__init__()\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # Here we just need to construct the components of our network. We don't need to connect them together yet.\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_size) # embedding layer\n",
    "        \n",
    "        self.hidden_layer = nn.Linear(embedding_size*sequence_length, hidden_size) # Fully connected hidden layer\n",
    "        self.activation = nn.ReLU() # Hidden layer\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes) # Fully connected output layer\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward (self, input_words):\n",
    "        # Input dimensions are:  (batch_size, seq_length)\n",
    "        embedded_words = self.embedding_layer(input_words)  # (batch_size, seq_length, embedding_size)\n",
    "\n",
    "        # flatten the sequence of embedding vectors for each document into a single vector.\n",
    "        embedded_words = embedded_words.reshape(embedded_words.shape[0], sequence_length*self.embedding_size)  # batch_size, seq_length*embedding_size\n",
    "\n",
    "        z = self.hidden_layer(embedded_words)   # (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        h = self.activation(z)  # do ReLU activation function on hidden layer outputs\n",
    "\n",
    "        output = self.output_layer(h)   \n",
    "\n",
    "        # Notice we haven't applied a softmax activation to the output layer -- it's not required by Pytorch's loss function.\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f22db-b953-4f98-920f-3f9a2b1e3707",
   "metadata": {},
   "source": [
    "Now the class is complete. \n",
    "\n",
    "TO-DO 2c: In the next cell, create a NN with the FFTextClassifier class we wrote. (unmarked)\n",
    "\n",
    "Hint: `ff_classifier_model = FFTextClassifier(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a52d795a-adbc-4c48-aadf-f911520ac42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vectorizer.vocabulary_) + 1\n",
    "embedding_size = 10  # number of dimensions for embeddings\n",
    "hidden_size = 8 # number of hidden units\n",
    "\n",
    "ff_classifier_model = FFTextClassifier(vocab_size, 40, embedding_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6c48d-f2b4-45e6-838e-d08c895f7e86",
   "metadata": {},
   "source": [
    "After desigining our network, we need to create a training function to calculate the loss for each input and perform backpropagation to optimise the network.\n",
    "During training, the weights of all the layers will be updated.\n",
    "\n",
    "Below, we build a training function to train the NN over a fixed number of epochs (an epoch is one iteration over the whole training dataset).\n",
    "The function also prints the performance of both training and development/validation set after each epoch.\n",
    "\n",
    "Here we use cross-entropy loss, which is the standard loss function for classification that we also used for logistic regression. The module `nn.CrossEntropyLoss()` operates directly on the output of our output layer, so we don't have to implement the softmax layer within the forward() method.\n",
    "\n",
    "Cross Entropy Loss: https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "\n",
    "The optimizer object implements a particular algorithm for updating the weights. Here, we will use the Adam optimizer, which is a variant of stochastic gradient descent method that tends to find a better solution in a smaller number of iterations than standard SGD.\n",
    "\n",
    "Optimization: https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "The cell below defines a training function for our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c682c18-b30c-489f-9c22-fb5662fc7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "def train_nn(num_epochs, model, train_dataloader, dev_dataloader, weight_decay=0):\n",
    "    \n",
    "    learning_rate = 0.0005  # learning rate for the gradient descent optimizer, related to the step size\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()  # create loss function object\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)  # create the optimizer. weight_decay added for later to-do\n",
    "    \n",
    "    global epoch_train_losses\n",
    "    global epoch_dev_losses\n",
    "    epoch_train_losses = []\n",
    "    epoch_dev_losses = []\n",
    "    \n",
    "        \n",
    "    for e in range(num_epochs):\n",
    "        # Track performance on the training set as we are learning...\n",
    "        total_correct = 0\n",
    "        total_trained = 0\n",
    "        train_losses = []\n",
    "\n",
    "        model.train()  # Put the model in training mode.\n",
    "\n",
    "        for i, (batch_input_ids, batch_labels) in enumerate(train_dataloader):\n",
    "\n",
    "            optimizer.zero_grad()  # Reset the optimizer\n",
    "\n",
    "            # Use the model to perform forward inference on the input data.\n",
    "            # This will run the forward() function.\n",
    "            output = model(batch_input_ids)\n",
    "\n",
    "            # Compute the loss for the current batch of data\n",
    "            batch_loss = loss_fn(output, batch_labels)\n",
    "\n",
    "            # Perform back propagation to compute the gradients with respect to each weight\n",
    "            batch_loss.backward()\n",
    "\n",
    "            # Update the weights using the compute gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Record the loss from this sample to keep track of progress.\n",
    "            train_losses.append(batch_loss.item())\n",
    "\n",
    "            # Count correct labels so we can compute accuracy on the training set\n",
    "            predicted_labels = output.argmax(1)\n",
    "            total_correct += (predicted_labels == batch_labels).sum().item()\n",
    "            total_trained += batch_labels.size(0)\n",
    "\n",
    "        train_accuracy = total_correct/total_trained*100\n",
    "\n",
    "        print(\"Epoch: {}/{}\".format((e+1), num_epochs),\n",
    "              \"Training Loss: {:.4f}\".format(np.mean(train_losses)),\n",
    "              \"Training Accuracy: {:.4f}%\".format(train_accuracy))\n",
    "        \n",
    "        epoch_train_losses.append(np.mean(train_losses))\n",
    "        \n",
    "        # Compute accuracy on dev set after this training epoch\n",
    "        \n",
    "        model.eval()  # Switch model to evaluation mode - turn off any random steps such as dropout\n",
    "        total_correct = 0\n",
    "        total_trained = 0\n",
    "        dev_losses = []\n",
    "\n",
    "        for dev_input_ids, dev_labels in dev_dataloader:\n",
    "            \n",
    "            dev_output = model(dev_input_ids)  # make prediction on dev set\n",
    "            \n",
    "            dev_loss = loss_fn(dev_output, dev_labels)  # run the loss function on the predictions\n",
    "            \n",
    "            dev_losses.append(dev_loss.item())  # append losses to our dev_loss list\n",
    "            \n",
    "            # Count the number of correct predictions\n",
    "            predicted_labels = dev_output.argmax(1)\n",
    "            total_correct += (predicted_labels == dev_labels).sum().item()\n",
    "            total_trained += dev_labels.size(0)\n",
    "            \n",
    "        dev_accuracy = total_correct/total_trained*100  # calculate accuracy on the dev-set predictions\n",
    "        \n",
    "        print(\"Epoch: {}/{}\".format((e+1), num_epochs),\n",
    "              \"Validation Loss: {:.4f}\".format(np.mean(dev_losses)),\n",
    "              \"Validation Accuracy: {:.4f}%\".format(dev_accuracy))\n",
    "        \n",
    "        epoch_dev_losses.append(np.mean(dev_losses))  # take a mean of the dev_losses across all batches and append to list\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473f92-78d4-4a5d-94cc-749165e3896e",
   "metadata": {},
   "source": [
    "**TO-DO 2d:** Modify the training function above to return the training and development (or 'validation') losses at each epoch. Train the network for 15 epochs and plot the losses. Describe what the plot shows, and how you could use this information to improve the training process. **(8 marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d8da6",
   "metadata": {},
   "source": [
    "**ANSWER:** The graph shows that for epochs 1-11, the model is underfit to the training data. Thus, performance on the validation set improves, demonstrated by the decreasing cross-entropy loss. From epoch 12-15, the model has converged to an optimal solution and is now overfitting the training data. This can be seen by the performance on the validation set plateauing and the performance on the training set continuing to increase. Training should be stopped after 11 epochs to avoid overfitting of the weights to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ac7c289-fae8-4045-b18c-8db7e678214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15 Training Loss: 1.0125 Training Accuracy: 45.0466%\n",
      "Epoch: 1/15 Validation Loss: 1.0126 Validation Accuracy: 43.3000%\n",
      "Epoch: 2/15 Training Loss: 1.0042 Training Accuracy: 46.3049%\n",
      "Epoch: 2/15 Validation Loss: 1.0078 Validation Accuracy: 44.8500%\n",
      "Epoch: 3/15 Training Loss: 0.9905 Training Accuracy: 49.0343%\n",
      "Epoch: 3/15 Validation Loss: 0.9972 Validation Accuracy: 48.1500%\n",
      "Epoch: 4/15 Training Loss: 0.9664 Training Accuracy: 52.2284%\n",
      "Epoch: 4/15 Validation Loss: 0.9830 Validation Accuracy: 51.4500%\n",
      "Epoch: 5/15 Training Loss: 0.9372 Training Accuracy: 54.9030%\n",
      "Epoch: 5/15 Validation Loss: 0.9619 Validation Accuracy: 52.7500%\n",
      "Epoch: 6/15 Training Loss: 0.9090 Training Accuracy: 57.0141%\n",
      "Epoch: 6/15 Validation Loss: 0.9550 Validation Accuracy: 54.0000%\n",
      "Epoch: 7/15 Training Loss: 0.8827 Training Accuracy: 58.7044%\n",
      "Epoch: 7/15 Validation Loss: 0.9361 Validation Accuracy: 54.4500%\n",
      "Epoch: 8/15 Training Loss: 0.8574 Training Accuracy: 60.2411%\n",
      "Epoch: 8/15 Validation Loss: 0.9290 Validation Accuracy: 56.0000%\n",
      "Epoch: 9/15 Training Loss: 0.8343 Training Accuracy: 61.4732%\n",
      "Epoch: 9/15 Validation Loss: 0.9244 Validation Accuracy: 55.7000%\n",
      "Epoch: 10/15 Training Loss: 0.8122 Training Accuracy: 62.7009%\n",
      "Epoch: 10/15 Validation Loss: 0.9218 Validation Accuracy: 56.4500%\n",
      "Epoch: 11/15 Training Loss: 0.7915 Training Accuracy: 63.9461%\n",
      "Epoch: 11/15 Validation Loss: 0.9209 Validation Accuracy: 56.3000%\n",
      "Epoch: 12/15 Training Loss: 0.7715 Training Accuracy: 65.3118%\n",
      "Epoch: 12/15 Validation Loss: 0.9199 Validation Accuracy: 56.6000%\n",
      "Epoch: 13/15 Training Loss: 0.7527 Training Accuracy: 66.2852%\n",
      "Epoch: 13/15 Validation Loss: 0.9096 Validation Accuracy: 55.6500%\n",
      "Epoch: 14/15 Training Loss: 0.7343 Training Accuracy: 67.2125%\n",
      "Epoch: 14/15 Validation Loss: 0.9158 Validation Accuracy: 56.3000%\n",
      "Epoch: 15/15 Training Loss: 0.7166 Training Accuracy: 68.3876%\n",
      "Epoch: 15/15 Validation Loss: 0.9219 Validation Accuracy: 56.7000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FFTextClassifier(\n",
       "  (embedding_layer): Embedding(43359, 10)\n",
       "  (hidden_layer): Linear(in_features=400, out_features=8, bias=True)\n",
       "  (activation): ReLU()\n",
       "  (output_layer): Linear(in_features=8, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###WRITE YOUR OWN CODE HERE\n",
    "train_nn(15, ff_classifier_model, train_loader, dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16da6baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Entropy Loss')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAHgCAYAAABJrX+JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAABSbUlEQVR4nO3dd3iUVeL28e9Jr4QSeui9BwjdgooCoqIU6dKL2Nb6s66r7+q6uquuglQBEQXFgthFxQLSQu+9hd4JhEDKef+YAaMGCDCTZ2Zyf65rLmaemXnmHiz3PO0cY61FREREAkuQ0wFERETE81TwIiIiAUgFLyIiEoBU8CIiIgFIBS8iIhKAVPAiIiIBKMTpAJ4SHx9vK1as6HQMERGRfLN48eKD1triuT0XMAVfsWJFkpOTnY4hIiKSb4wx28/3nHbRi4iIBCAVvIiISABSwYuIiASggDkGLyIiVy4jI4OUlBTS09OdjiI5REREkJCQQGhoaJ7fo4IXEZFzUlJSiI2NpWLFihhjnI4jgLWWQ4cOkZKSQqVKlfL8Pu2iFxGRc9LT0ylWrJjK3YcYYyhWrNgl71VRwYuIyB+o3H3P5fwzUcGLiIjPOHToEImJiSQmJlKqVCnKli177vGZM2cu+N7k5GTuv//+i35Gy5YtPRXXp+kYvIiI+IxixYqxbNkyAP7xj38QExPDI488cu75zMxMQkJyr66kpCSSkpIu+hm//fabR7L6Om3Bi4iIT+vXrx/Dhg2jWbNmPPbYYyxcuJAWLVrQsGFDWrZsyfr16wH46aefuOWWWwDXj4MBAwbQunVrKleuzBtvvHFufTExMede37p1a7p06ULNmjXp1asX1loAvvrqK2rWrEnjxo25//77z63Xn2gLXkREcvXc56tZs/u4R9dZu0whnr21ziW/LyUlhd9++43g4GCOHz/Or7/+SkhICN9//z1PPvkkH3/88V/es27dOmbPnk1qaio1atTg7rvv/stlZkuXLmX16tWUKVOGVq1aMXfuXJKSkhg6dCi//PILlSpVokePHpf9fZ2kghcREZ/XtWtXgoODATh27Bh9+/Zl48aNGGPIyMjI9T0dOnQgPDyc8PBwSpQowb59+0hISPjDa5o2bXpuWWJiItu2bSMmJobKlSufuyStR48ejB071ovfzjtU8CIikqvL2dL2lujo6HP3n3nmGa677jo+/fRTtm3bRuvWrXN9T3h4+Ln7wcHBZGZmXtZr/JWOwYuIiF85duwYZcuWBWDSpEkeX3+NGjXYsmUL27ZtA+CDDz7w+GfkBxW8iIj4lccee4wnnniChg0bemWLOzIykrfeeot27drRuHFjYmNjiYuL8/jneJs5e8agv0tKSrKaD15E5MqsXbuWWrVqOR3DcSdOnCAmJgZrLffccw/VqlXjwQcfdDRTbv9sjDGLrbW5XhuoLfjzsMd3Q4D8+BERkUszbtw4EhMTqVOnDseOHWPo0KFOR7pkOskuF1kZp8l6tT5nQmLILptEoaotoVxTKNMIwqKcjiciIl724IMPOr7FfqVU8LlITTvF1yXuJWLvYhpsXUmh7bMAsCYYU6oulGsGCU2hXBMoXAE0brOIiPgYFXwuCscVpsfwf3AsLYOZy3fxzKLVhO9dQlLwJq4/so2qB6YQstB9TWR0CdfWfUIT91Z+QwiNdPYLiIhIgaeCv4C4qFD6tKhInxYVWbf3aj5KTqHX0l0cPXmK5jH76JOwj5Zhmym0byms+8L1pqAQKFXPvZXvLv24ctrKFxGRfKWz6C9RRlY2P67bz/TkFGav309WtqVh+cL0rhtF+yI7idq3BHYugt1LICPN9aaYUq7d+QlNXYVfOhFCI7yeVUTkUukset91qWfRawv+EoUGB9G2Tina1inFgdTTzFi6i+mLd/LwV7t5KjSUdnU60vXqe2lRMY6g/ashZRHsXAgpC2Ht566VBIVC6fq/F365phCXcOEPFhEpIIKDg6lXrx4ZGRmEhIRw11138eCDDxIU5LkLv7Zt28Ytt9zCqlWrPLZOT3jxxRd58sknPbIubcF7gLWWFSnH+DB5JzOX7yY1PZOyhSPp0jiBLo0TKFfUfeb9if2/l/3ORbB7KWSecj0XW8a1lV+/O9Ror136IuIIX9iCj4mJ4cSJEwDs37+fnj170qpVK5577jmPfYavFnzO7/5nug7eAcYYGpQrzAt31GPRU234X/dEKheP5o0fN3L1y7PpMXY+nyxJ4VRYMah1C9z4PAz4Gp7YCYNnQ/uXoUJLV/lP6wGjr4bVMyA72+mvJiLiqBIlSjB27FhGjBiBtZasrCweffRRmjRpQv369RkzZgwA3bt358svvzz3vn79+vHRRx+d9/U5paen079/f+rVq0fDhg2ZPXs24BoGt2PHjrRu3Zpq1aqd+4Gxbds2atasSb9+/ahevTq9evXi+++/p1WrVlSrVo2FCxcCcPLkSQYMGEDTpk1p2LAhn3322bn1durUiXbt2lGtWjUee+wxAB5//HFOnTpFYmIivXr1uuK/O+2i97CI0GA6JpalY2JZdh09xSeLU5i+OIWHPlzO3z9bzS31S9M1qRyNyhfGBIdC2UauW7OhkJUJK6fDr/+F6X0hvgZc8wjU6QTB+kclIvns68dh70rPrrNUPWj/0iW9pXLlymRlZbF//34+++wz4uLiWLRoEadPn6ZVq1bcdNNNdOvWjQ8//JAOHTpw5swZfvjhB0aNGsXbb7+d6+tNjr2kI0eOxBjDypUrWbduHTfddBMbNmwAYOHChaxatYqoqCiaNGlChw4diI+PZ9OmTUyfPp0JEybQpEkT3n//febMmcPMmTN58cUXmTFjBi+88ALXX389EyZM4OjRozRt2pQ2bdoAsGzZMpYuXUp4eDg1atTgvvvu46WXXmLEiBEsW7bMI3/V2oL3orKFI7nvhmr89Ehrpg1pTts6pfhs2W46j/qNG179mVE/bWbf8fTf3xAcAok94J4F0GUCBAXDJ4NhZBNYOgWycp8SUUSkoPjuu++YPHkyiYmJNGvWjEOHDrFx40bat2/P7NmzOX36NF9//TXXXHMNkZGR5319TnPmzKF3794A1KxZkwoVKpwr+BtvvJFixYoRGRlJp06dmDNnDgCVKlWiXr16BAUFUadOHW644QaMMdSrV+/cJDXfffcdL730EomJibRu3Zr09HR27NgBwA033EBcXBwRERHUrl2b7du3e/zvSpuF+SAoyNC8cjGaVy7Gcx3r8NWKPUxfvJN/f7OOV75dx7XVi9M1qRw31CpBeEiwq9jrdobad8D6L+Hnl+Gze+Cnf8NVf4OGvSEk/KKfKyJyRS5xS9tbtmzZQnBwMCVKlMBay5tvvknbtm3/8rrWrVvz7bff8sEHH9C9e3eA877+bAlfjPnT+VBnH+ecZjYoKOjc46CgoHMT4Fhr+fjjj6lRo8Yf1rFgwYJ8maZWW/D5LCY8hDublGP6sJbMfqQ1d7euwto9qQx/bwnNX/yB0T9vJiPLfew9KAhq3QpDf4GeH0JMCfjyIfhfIswfDRmnHP0uIiLeduDAAYYNG8a9996LMYa2bdsyatQoMjJcezQ3bNjAyZMnAejWrRsTJ07k119/pV27dgAXfP1ZV199Ne+9996553fs2HGulGfNmsXhw4c5deoUM2bMoFWrVnnO3rZtW958803Onsy+dOnSi74nNDT0XNYrpYJ3UKX4aB5tW5O5j1/PpP5NSCxXmJe+XsdtI+ayfOfR319oDFRvC4O+hz4zoGgl+Ob/4PX6MPcNOJ37GZciIv7o7IlmderUoU2bNtx00008++yzAAwaNIjatWvTqFEj6taty9ChQ89t/d500038/PPPtGnThrCwsIu+/qzhw4eTnZ1NvXr16NatG5MmTTq3hd20aVM6d+5M/fr16dy5M0lJuZ6wnqtnnnmGjIwM6tevT506dXjmmWcu+p4hQ4ZQv359j5xkp8vkfMw3q/by7MxV7E89Td8WFXmkbQ1iwnM5krJtLvzyMmz5CSKLQovh0HQIRPjfnMUi4jt84TI5XzFp0iSSk5MZMWKE01EAH7pMzhgzwRiz3xiT60WGxuUNY8wmY8wKY0yjHM/1NcZsdN/6eiujL2pXtxSzHrqWPs0r8M68bdz46s/MWrPvry+s2Aru+gwGfu8aEvfHf8Lr9WD2i5B2OP+Di4iIT/HaFrwx5hrgBDDZWls3l+dvBu4DbgaaAf+z1jYzxhQFkoEkwAKLgcbW2iMX+rxA2YLPacmOIzzx8UrW70ulXZ1S/OO2OpSKO88Qt7uXwS+vuMbED4uBpoOh+T0QUzxfM4uIf9MWvO/ymS14a+0vwIU2JTviKn9rrZ0PFDbGlAbaArOstYfdpT4LaOetnL6sUfkifHH/VTzWrgaz1++nzas/8+68bWRn5/KjrEwidH8P7v4Nqt0Ec153bdF/8ySk7s3v6CIi4jAnT7IrC+zM8TjFvex8ywuk0OAghreuyrd/u4YG5eJ45rPVdBn9G+v3pub+hpJ1oOtEuHcR1LkdFox2nYz35SNwLCVfs4uIfwqUc7MCyeX8M/Hrs+iNMUOMMcnGmOQDBw44HcerKsZHM2VgM169swFbD56kwxu/8sq360jPyMr9DfHV4I7RcF8yNOgGiye5Lq+beR8c3pqf0UXEj0RERHDo0CGVvA+x1nLo0CEiIi5tFlKvnkVvjKkIfHGeY/BjgJ+stVPdj9cDrc/erLVDc3vd+QTiMfjzOXzyDC98uZaPl6RQsVgUL9xRj1ZV4y/8pqM7Ye7rsORdyM6E+nfC1Q+7fgiIiLhlZGSQkpJCenr6xV8s+SYiIoKEhARCQ0P/sPxCx+CdLPgOwL38fpLdG9bapu6T7BYDZ8+qX4LrJLsLnhpekAr+rLmbDvLUpyvZdiiNTo3K8nSH2hSNDrvwm47vgd/ehOQJkJkOdTvB9U9D0cr5E1pERDzGkYI3xkzFtTUeD+wDngVCAay1o41rvL8RuE6gSwP6W2uT3e8dAJydEPcFa+3Ei31eQSx4gPSMLEb8uInRP28mNiKEpzvUplOjsn8ZXvEvThyAeSNg0XjIzoIb/u6a8CYoOH+Ci4jIFXNsCz4/FdSCP2v93lSe+GQFS3YcpVXVYrxwez0qxkdf/I3HdsEXD8LGb6FcM7htBBSv7v3AIiJyxTQffAFQo1QsHw1ryT9vr8uKncdo+/ovjJy9iTOZF5lTPq4s9PwA7hgLB9bD6KtgzmuuqWtFRMRvaQs+AO07ns4/Zq7m61V7qVEylhc71aNxhSIXf2PqPvjqYVj7OZROhNvfcl12JyIiPklb8AVMyUIRjOrdmHF3JXE8PYMuo3/jmRmrOJ5+kRmKYktCtynQdZLrmvkx17qmqM08ky+5RUTEc1TwAezG2iWZ9dC19GtZkSkLtnPjqz/zzao9F7++tc4dcM9C10A5P70I466D3Ref5lBERHyHCj7AxYSH8OytdZgxvBVFo8MZNmUJgycvZvfRi8wlH10MOo+H7lPh5EEYdwN8/xxk6NpYERF/oGPwBUhmVjYT5m7l1VkbCDaGR9rW4K4WFQkOusgldaeOwLdPw7IpEF8DOo6Eck3yJ7SIiJyXjsELACHBQQy5pgqzHryWpIpFee7zNXR6ay7bDp688Bsji8DtI6H3x3DmJLx9I3z7FJxJy5/gIiJyyVTwBVC5olFM6t+E/3VPZPvhNHqNX8C+43nY9V61DQyfB0n9XYPkjG4F2+Z6P7CIiFwyFXwBZYyhY2JZJg9oypG0M/SdsPDiZ9kDRBSCW16Dvp+DzYZJN7tmqjt9wvuhRUQkz1TwBVz9hMKM7t2YTftPMGRyMqczzzM73Z9VusY193yzu13D3b7VAjbP9m5YERHJMxW8cE314vynawPmbznMQx8sJys7jydehkVD+5dgwDcQEgbv3u6ajjb9mFfziojIxangBYDbG5blqZtr8eXKPTz/+epLmwu6fHMYNgdaPQBLp8DI5rDhW++FFRGRi1LByzmDr6nMoKsq8c687Yz6efOlvTk0Em58HgZ9DxFx8P6d8MlQSLvgLL8iIuIlKnj5gydvrkXHxDK8/M16pifvvPQVlG0MQ3+Ga/8PVn0EI5vBmpmeDyoiIhekgpc/CAoyvNKlAVdVjefxT1Yye93+S19JSDhc9yQMng2xpeDDPjC9n2sOehERyRcqePmLsJAgRvdpTK3SsQx/bwlLdxy5vBWVrg+Df4Trn4F1X8LIprDyIwiQ0RNFRHyZCl5yFRMewsR+TSkeG86ASYvYcuAyr3MPDoVrHoGhv0DRSvDxQJjWU1vzIiJepoKX8yoeG87kAU0JMoa7Jixkf15GuzufErVg4Cy46Z+w+UfXADnH93gurIiI/IEKXi6oYnw0E/s34fDJM/SduChvo92dT1AwtLwP+nwKx3fDxPZw9DJO5BMRkYtSwctFnR3tbuO+VIZOXpz30e7Op0JL6DPDdQndpJvhyDZPxBQRkRxU8JIn11Qvzitd6zNvyyEe+nA52Xkd7e58yjWBvp9B+nGYeDMcusTr7kVE5IJU8JJndzRM4Mmba/Llij08/8WaSxvtLjdlGkK/LyAz3bW7/sB6zwQVEREVvFyawVdXZuBVlZj02zZG/7zlyldYqh70+9J16dzEm2Hvqitfp4iIqODl0hhjeOrmWtzWoAz//mYdHy1OufKVlqgF/b+G4DB45xbYvezK1ykiUsCp4OWSBQUZ/tPVNdrd/328gtnrL2O0uz+Lrwr9v4SwGJh8G6QkX/k6RUQKMBW8XJawkCBG9W5EzVKxDJ+yhGU7j175SotWhv5fQWQRmHw7bJ935esUESmgVPBy2WIjQpnU3wOj3eVUuLxrd31sSZjSGbb+euXrFBEpgFTwckWKx4bzzoCmGLjy0e7OKlQG+n0FhcvBe11g0w9Xvk4RkQJGBS9XrJInR7s7K7ak6+z6YtVganfY8O2Vr1NEpABRwYtH1E8ozCj3aHfD3vXAaHcA0fHQdyaUqA3TesHaz698nSIiBYQKXjzm2urFeblLfX7b7KHR7gCiirpKvkwifNgXVn185esUESkAVPDiUZ0aJfBEew+OdgcQEeeaoKZcM/h4ECyfduXrFBEJcCp48bgh1/w+2t2YXzww2h1AeCz0/ggqXgWfDoMlkz2zXhGRAKWCF487O9rdrQ3K8NLX6/jYE6PdAYRFQ88PoeoNMPM+WDjOM+sVEQlAKnjxCtdod/VpVbUY//fxCn7yxGh3AKGR0P19qHEzfPUIzBvpmfWKiAQYFbx4TXhIMKN7N6ZGqVju9tRodwAh4dD1Hah1G3z7JPz6qmfWKyISQFTw4lWxEaFM7N+E+NgwBkxaxNaDJz2z4pAw6DIR6nWFH56Dn15yzUgnIiKACl7yQYnYCCYPaOYe7W4B+1M9MNodQHAI3DEGEnvBT/+CH55XyYuIuKngJV9Uio9mQr8mHDpxhn4TFpHqidHuAIKC4bYR0LgfzHkVvntaJS8iggpe8lGDcq7R7jbsS+WR6cs9c408QFAQ3PI6NB0K80bAV49CdrZn1i0i4qdU8JKvrq1enP9rV5NvV+9j8rztnluxMdD+39DyPlg0Dr54QCUvIgVaiNMBpOAZdHUl5m85xAtfrqVxhSLULRvnmRUbAzf+PwiJgF9egawM6DjStRtfRKSA0Ra85DtjDP/p2oBiMWHc8/4Szx2Pd60crn8arnsalk+FTwa7il5EpIBRwYsjikSH8UaPhqQcOcUTn6z03PH4s659FG583jU5zfR+kHnGs+sXEfFxKnhxTJOKRXnoxup8sWIPUxfu9PwHtHoA2v0b1n0BH/SG9OOe/wwRER+lY/DiqLuvrcL8LYd47vPVNCxfmFqlC3n2A5oPcw2K88WD8EoVqNwaat7iGuo2prhnP0tExIcYj+8adUhSUpJNTk52OoZchoMnTtP+f78SGxHC5/deRXS4F3537loMqz6BtTPh6A4wQVCuOdS6FWp2gCIVPP+ZIiJeZoxZbK1NyvU5Fbz4gt82H6TX+AXc0bAsr96Z6L0Pshb2rnTttl/7Bexf7Vpeqr677G+BErVcJ+uJiPg4Fbz4hddmbeB/P2zklS716ZpULn8+9NBmWPelq/B3LgQsFK3sKvpat0LZJNdAOiIiPkgFL34hK9vSa/x8lu88xsx7W1GtZGz+Bkjd+3vZb/0FsjMhppRrF36tW6Di1RAcmr+ZREQuQAUvfmPf8XRu/t+vxMeEM+OeVkSGOTRIzamjsPE7WPs5bPoeMtIgIg6qt3Nt3Ve9AcKinckmIuKmghe/8suGA9w1YSHdm5Tjpc71nY4DGadg84+uY/YbvoZTRyAkEqpc79qNX70tRBV1OqWIFEAXKnhdJic+55rqxRneugpv/bSZFlWK0TGxrLOBQiNdu+lrdoCsTNg+17Ubf92XsP5LMMFQ8arfz8gvVMbZvCIiaAtefFRmVjbdx85n7Z7jfH7fVVQuHuN0pL+yFnYvcW3Zr/0cDm10LS/b2H2S3m0QX9XZjCIS0LSLXvzS7qOnuPmNXykTF8knw1sSEerjk8YcWO8q+nVfwO6lrmVNBrlG0wvWzjIR8bwLFbyu/xGfVaZwJP/t2oA1e47zwpdrnY5zccVrwDWPwJCf4MHV0OxuWDQepvWE0yecTiciBYwKXnzaDbVKMvjqSrw7fztfrdzjdJy8i0uA9i9Bh//Cplkw6WbXZXgiIvlEBS8+79G2NWlQrjD/99EKdhxKczrOpWkyCHp8AAc3wfg2sN8P9kSISEDwasEbY9oZY9YbYzYZYx7P5fkKxpgfjDErjDE/GWMScjyXZYxZ5r7N9GZO8W1hIUGM6NEQDNw3dQlnMrOdjnRpqt8E/b9yzUv/9k2w5SenE4lIAeC1gjfGBAMjgfZAbaCHMab2n172H2CytbY+8DzwrxzPnbLWJrpvt3krp/iHckWjeKVLA5anHOPf36xzOs6lK5MIg7537bqf0hmWve90IhEJcN7cgm8KbLLWbrHWngGmAR3/9JrawI/u+7NzeV7knHZ1S9GvZUXenrOVWWv2OR3n0hUuBwO+cV0zP+NumP0v16V2IiJe4M2CLwvszPE4xb0sp+VAJ/f9O4BYY0wx9+MIY0yyMWa+Meb23D7AGDPE/ZrkAwcOeDC6+Konbq5J3bKFeGT6cnYdPeV0nEsXEQc9p0NiL/j5JVfRZ55xOpWIBCCnT7J7BLjWGLMUuBbYBWS5n6vgvravJ/C6MabKn99srR1rrU2y1iYVL14830KLc8JDghnRoxFZ2Zb73l9CRpafHY8HCAmDjiPhuqdg+VSY0sk19r2IiAd5s+B3ATnn/ExwLzvHWrvbWtvJWtsQeMq97Kj7z13uP7cAPwENvZhV/EjF+Ghe7FSPJTuO8t/vNjgd5/IYA9c+BneMgR3zYUJbOLrD6VQiEkC8WfCLgGrGmErGmDCgO/CHs+GNMfHGmLMZngAmuJcXMcaEn30N0ApY48Ws4mdua1CGHk3LM/rnzfy0fr/TcS5fg+7Q5xM4vsd1Gd2uJU4nEpEA4bWCt9ZmAvcC3wJrgQ+ttauNMc8bY86eFd8aWG+M2QCUBF5wL68FJBtjluM6+e4la60KXv7g2VtrU7NULA99uJy9x9KdjnP5Kl0DA7+D4HCY1AHWf+10IhEJABqLXvzapv0nuPXNOdRLiOP9Qc0ICXb6tJIrkLoPpnaDPcuh/cvQdLDTiUTEx2kseglYVUvE8M/b67Jw62He+GGj03GuTGxJ6PclVG8HXz0C3z4F2X54EqGI+AQVvPi9zo0T6NI4gTdnb2LupoNOx7kyYdHQbQo0HQrzRsD0vpDhh5cDiojjVPASEJ7vWIcqxWN4YNoy9qf68fF4gKBgaP9vaPsv1/Sz79wKJ/38h4uI5DsVvASEqLAQRvZsRGp6Bg9+sIysbD8/t8QYaDEc7pwMe1e6zrA/uMnpVCLiR1TwEjBqlIrludvqMHfTIUb9FCBlWPs213H506nwdhvYPs/pRCLiJ1TwElC6NSlHx8QyvDprAwu2HHI6jmckJMGgWRBVDCbfBqs+djqRiPgBFbwEFGMML9xRj/JFo7h/2lIOnTjtdCTPKFoZBs6Csknw0QCY85omqhGRC1LBS8CJCQ9hRM9GHDmZwcPTl5Pt78fjz4oqCn0+hbqd4ft/wBcPQlam06lExEep4CUg1S0bxzO31OKn9QcY9+sWp+N4TmgEdBoPVz8Miye6BsY5nep0KhHxQSp4CVi9m1fg5nqlePnb9SzefsTpOJ4TFAQ3/B1u/R9sng0T28Px3U6nEhEfo4KXgGWM4V+d6lOmcAT3T13K0bQAm3e9cT/o9SEc3uq6jG7faqcTiYgPUcFLQIuLDGVEj0bsT03n4Q8D6Hj8WVXbwIBvXCfcvd0WNv/odCIR8REqeAl4DcoV5qmba/HDuv2M+nmz03E8r1Q9GPQ9FKkA73WFT4a6ZqTL8PMR/UTkioQ4HUAkP/RtWZHFO47y3+/W07B8YVpWiXc6kmfFlYX+X8Osv8PqT2DFNAiLhRrtoHZH15Z+aKTTKUUkH2m6WCkwTp7O5LYRczh2KoMv77+akoUinI7kHZlnYNsvsHoGrPsCTh2B0Gio3tZV9tVudE1qIyJ+70LTxargpUDZuC+V20bMpW7ZQrw/uDmh/jx/fF5kZcC2ObDmM9fENWkHITTKVfK1O0K1thAe43RKEblMKniRHD5btosHpi1j8NWVeKpDbafj5J+sTNjxm6vs18yEk/shJMK1+7727a4t/IhCTqcUkUtwoYLXMXgpcDomliV52xHG/bqVxhWK0K5uaacj5Y/gEKh0jevW/mXYucC1G3/tTNeu/OAwqHKDa8u+RnuILOx0YhG5AtqClwLpdGYWd46ex5YDJ5l531VUii/Ax6SzsyFlkXvL/jM4ngJBoVDlOnfZ3+waJldEfI520YvkIuVIGre8OYdShSL4dHgrIsOCnY7kvOxs2L0E1sxwlf3RHRDk3vKvfTvUvAWiizmdUkTcVPAi5zF7/X4GTFpEl0YJvNK1gdNxfIu1sHupe8t+BhzZBiYYKl7l2rKvdSvElHA6pUiBpoIXuYBXv1vPGz9u4t+d69GtSXmn4/gma2HvClfZr54BhzeDCYIKrVxlX/FqiK/uGidfRPKNCl7kArKyLX0nLGThtsN8cndL6paNczqSb7MW9q9xFf2aGXBwg2t5WCyUbQhlG7tvSVCogJzAKOIQFbzIRRw6cZoOb8whLCSIz++7irjIUKcj+Y+Dm1wn6e1Khl2LYe8qyM5wPRdbBhIa/176ZRpCeKyzeUUCiApeJA8Wbz9CtzHzaF2jBOPuaowxxulI/ikjHfaudJX92dI/vMX9pIHiNV1lf7b4S9SGYP2gErkcKniRPJowZyvPf7GGx9vXZNi1VZyOEzjSDsOuJe7Sdxd/2iHXcyGRULrBH0u/cAXQDyyRi1LBi+SRtZZ731/K16v28P7g5jSvrEvCvMJaOLodUpJ/L/49yyDTPQNeVPzvu/UTGkOZRroWXyQXKniRS5CankHHEXM5np7JV/dfRYlAnZTG12RluE7e27UYUtxb+gfWAe7/RxWt7Dpxr2xjKNsIilWFyCLa0pcCTQUvconW703l9pFzqZcQx/uDmhES6JPS+Kr0464t+12Lf9/aT939+/Oh0RCXAIXLuf6MK+e6nX0cW8Y1RK9IgFLBi1yGT5ak8NCHyxl6bWWeaF/L6Thy1vHdsHuZa+CdYztdt6M74ViKa7a8nEwwFCqTo/zP/hgo9/tjzaYnfkyTzYhchk6NEkjefoQxP2+hcfki3FSnlNORBFyFXahM7s+dSYPju1xD7B5zl/7Z8t85H1bvhuzMP74nsshft/xzPo4ursMA4hnZWYDJtwGhVPAiF/D3W2qzMuUYD09fzhelYqlQrABPSuMPwqIgvprrlpvsLEjdm6P8d7j+PLYTjmyFrb/AmdQ/vic43F36Ca7pdEOjITQSwqIhNMr1meeWue+HRbmey/l8WJTrigGN9lewpO6DzT/Aph9g84/QbQpUbJUvH62CF7mAiNBg3urViFvenMPdU5bwyfCWRIRqUhq/FRQMcWVdt9xYC+nH/rjb/9jZHwG74MR+yDjp2lOQccp1/1KFRF7gR0HkH38gnPsREf37LTQKwmJcrwmLdr/evVw/HpyXeQZSFsKm7123vStdy6NLQPW2+TrQk47Bi+TBj+v2MWBSMt2SyvHvLvWdjiO+wlp30afBmZO/l/6ZNNeyjLTf7585eYFlp36/fybNtY6MU79fNphXoVEX+EHg/uEQFnPhHw3hhVyDD+nHQt4d2e4u9B9+3wsUFALlmkPVG1y3kvW88neqY/AiV+j6miW557oqjJy9mcYVi3BnUjmnI4kvMMZdmlEQHe/59Wdn/f5D4OwtIw3OnHD9EDhz0v2D4mQur8nxOO3QX99zIcVrQqu/Qb0uGmUwNxmnYNvc37fSD210LY8r7/o7q9rGNcVyRCFHY6rgRfLooRtrsHTHUZ6ZsYq6ZeKoXcbZ/3ilAAgKdu3S9fRu3exsyDzlLvwTf/xBcGwnzB8NM4bB7Beh1f3QsLfr8EFBZa1rUqWzhb5tLmSdhpAI1/TJTQa6Sr1YVZ86IVO76EUuwcETp+nwxq9EhgYz876rKBShrRsJQNbChm/h1/+6jidHF4fmw11FFlFAZltMPwZbfnYV+uYfXT98AOJruMq86vWu6ZId/uGj6+BFPGjRtsN0HzufG2qWYEwfTUojAcxa2D4Xfn3VdSZ4eCFoMshV9jHFnU7nWdnZsHe56zj6ph9g5wKwWa7vXPlaqOI+ll64vNNJ/0AFL+Jh43/dwj+/XMtTN9di8DWVnY4j4n27l8Kc12DNTAgJh0Z3Qcv7fK7wLsnJg66t87MnyJ0dKKl0A/dWehtIaOLT5yHoJDsRDxt4VSUWbz/CS9+so0G5wjStpIlQJMCVaQh3ToaDG2Hu65A8wXWrdydc9TcoXsPphBeXneUa7njjd7BplmtERCxEFXNvobeBKtdBTAmnk3qEtuBFLlNqega3jZjLydOZfHH/VZSI1aQ0UoAcS4HfRsDiSa7L+Wp2gKsfck0G5EtOHnTvdp/l+vPUYTBBri3zqje6druXTvTbywK1i17ES9buOc4db80lsVxhpgzUpDRSAJ08CAtGw8KxrhPTKreGqx5yXSbmxPkp2dmwZylsnOW67VoMWNeJglXbQLUbofJ1ATP9sApexIs+WpzCI9OXM7x1FR5rV9PpOCLOSD8OiyfCvJFwYp9rat+rH4Lq7b2/dZx22HUsfeMs1/H0tIOAgYQk11Z6tRv9eiv9QnQMXsSLujROYPH2w7z102YalS9Cm9olnY4kkv8iCkGrB6DpUFj2Hsz9H0zrCcVrwVUPQt3Onpu6Nzsb9q5wF/osSFkENhsii/6+lV7lBogu5pnP81PaghfxgPSMLDqP+o2dh9P44r6rKV8syulIIs7KyoTVn8KcV2H/GtfZ9i2vYNCcU0dhy+zft9JP7HMtL9MQqt3kupVp6BocqADRLnqRfLDjUBq3vPkr5YtF8dEwTUojAri2tjeeHTRnkWvSlRbDIWnghYdytRb2rfr9WPrZ69IjCkOV612FXvWGgDnj/XKp4EXyyfdr9jFocjI9mpbnX53qOR1HxHdYC9vmuLboN/8I4XHQdDA0v/v3cfzTj8OWn1y73Td+D6m7XctL1Xftdq92k+vYvqd29QcAHYMXySdtapfk7tZVGPXTZpIqFKFz4wSnI4n4BmOg0tWu29lBc379r+ukvLqd4eh22DEPsjNdo8dVuc69ld4GYks5nd4vqeBFPOzhG6uzdMcRnpqxktplClGrtCalEfmDs4PmHNjgOhlvxQeugXJa3Osq9XJNfXr0OH+hXfQiXrA/NZ1b35xDSFAQM+9tRbGYcKcjifiu7OyAvIQtP1xoF73+RkW8oERsBGP7JHHwxGnunrKEM5nZTkcS8V0qd6/Q36qIlzQoV5iXu9Rn4bbD/P2zVQTK3jIR8Q86Bi/iRR0Ty7JhXyojZ2+mRqlY+req5HQkESkgtAUv4mUP31iDG2uX5P99sYZfNhxwOo6IFBAqeBEvCwoyvNYtkeolY7n3/SVsOXDC6UgiUgCo4EXyQUx4COPuSiIkOIhB7yRz7FSG05FEJMCp4EXySbmiUYzq1YidR9K4b+pSMrN0Zr2IeI9XC94Y084Ys94Ys8kY83guz1cwxvxgjFlhjPnJGJOQ47m+xpiN7ltfb+YUyS/NKhfj/3Wsyy8bDvDiV+ucjiMiAcxrBW+MCQZGAu2B2kAPY0ztP73sP8Bka2194HngX+73FgWeBZoBTYFnjTFFvJVVJD91b1qefi0rMmHuVj5YtMPpOCISoLy5Bd8U2GSt3WKtPQNMAzr+6TW1gR/d92fneL4tMMtae9haewSYBbTzYlaRfPV0h1pcXS2ep2esYtG2w07HEZEA5M2CLwvszPE4xb0sp+VAJ/f9O4BYY0yxPL5XxG+FBAcxokcjyhWJYti7i0k5kuZ0JBEJME6fZPcIcK0xZilwLbALyMrrm40xQ4wxycaY5AMHdH2x+Je4qFDG9U3iTFY2g95J5uTpTKcjiUgA8WbB7wLK5Xic4F52jrV2t7W2k7W2IfCUe9nRvLzX/dqx1toka21S8eLFPRxfxPuqFI9hZM9GbNiXyoMfLCM7W8PZiohneLPgFwHVjDGVjDFhQHdgZs4XGGPijTFnMzwBTHDf/xa4yRhTxH1y3U3uZSIB55rqxXmqQ22+W7OP177f4HQcEQkQXit4a20mcC+uYl4LfGitXW2Med4Yc5v7Za2B9caYDUBJ4AX3ew8D/w/Xj4RFwPPuZSIBaUCrinRLKsebP25i5vLdTscRkQCg+eBFfMSZzGx6jZ/PipRjTB/WgvoJhZ2OJCI+TvPBi/iBsJAgRvVuTHxMOIMnJ7PveLrTkUTEj6ngRXxIfEw44/smkZqeyZB3F5OekeeLSkRE/kAFL+JjapUuxKt3JrJ851Ee/3gFgXIYTUTylwpexAe1q1uKR26qzoxluxn182an44iIHwpxOoCI5O6e66qyft8JXvl2PdVLxNKmdkmnI4mIH9EWvIiPMsbwSpf61CsbxwPTlrJ+b6rTkUTEj6jgRXxYRGgwY/skER0ewsB3FnH45BmnI4mIn1DBi/i4UnERjL0rif2pp7l7ymLOZGY7HUlE/IAKXsQPJJYrzMud67Ng62GenblaZ9aLyEXpJDsRP3F7w7Ks35fKqJ82U7NULH1bVnQ6koj4MG3Bi/iRR2+qQZtaJXj+izXM2XjQ6Tgi4sNU8CJ+JCjI8Hr3hlQtHsPw9xaz9eBJpyOJiI+6aMEbY142xhQyxoQaY34wxhwwxvTOj3Ai8lcx4SGM75tEcJBh4DuLOHYqw+lIIuKD8rIFf5O19jhwC7ANqAo86s1QInJh5YpGMap3Y3YcSuP+qUvJytZJdyLyR3kp+LMn4nUApltrj3kxj4jkUfPKxXi+Y11+3nCAf3211uk4IuJj8nIW/RfGmHXAKeBuY0xxQPNYiviAns3Ks2FfKuPnbKV6qVjuTCrndCQR8REX3YK31j4OtASSrLUZwEmgo7eDiUjePN2hFldVjeepT1eSvO2w03FExEfk5SS7rkCGtTbLGPM0MAUo4/VkIpInIcFBjOzZiIQiUQybspiUI2lORxIRH5CXY/DPWGtTjTFXAW2At4FR3o0lIpciLiqUcXclcTozm4GTkjmerjPrRQq6vBR8lvvPDsBYa+2XQJj3IonI5ahaIoZRvRqz+cAJ7nlvCRlZGrNepCDLS8HvMsaMAboBXxljwvP4PhHJZ1dVi+eFO+ry68aDGrNepIDLS1HfCXwLtLXWHgWKouvgRXxWtyblGd66Cu8v2MG4X7c4HUdEHHLRy+SstWnGmM1AW2NMW+BXa+133o8mIpfrkZtqsP1wGi9+tY5yRaJoX6+005FEJJ/l5Sz6B4D3gBLu2xRjzH3eDiYily8oyPDfrg1oWL4wf/tgGUt3HHE6kojks7zsoh8INLPW/t1a+3egOTDYu7FE5EpFhAYz7q4kShQKZ/DkZHYe1uVzIgVJXgre8PuZ9LjvG+/EERFPio8JZ2K/JpzJzGbAJE1MI1KQ5KXgJwILjDH/MMb8A5iP61p4EfEDVUvEMrpPY7YePKnL50QKkLwMVfsq0B847L71Bz70ci4R8aCWVeL5V6d6zNl0kKc/XaXL50QKgLxMNoO1dgmw5OxjY8wOoLy3QomI53VNKseOw2m8+eMmKsZHc3frKk5HEhEvylPB50LH4EX80EM3VmfboTT+/c06yheNokN9XT4nEqgud0Q67d8T8UPGGF7pUp/GFYrw4IfLWKLL50QC1nm34I0xb5J7kRugsLcCiYh3RYQGM7ZPYzqN+o3B7yQz455WlCsa5XQsEfGwC23BJwOLc7klAxroRsSPFYsJZ0K/JmRmW/pNXMixNF0+JxJoTKCcTZuUlGSTk5OdjiHiV+ZvOUSftxfQpGJRJvVvSliI5pES8SfGmMXW2qTcntN/zSIFWPPKxXipU31+23yIpz5dqcvnRALI5Z5FLyIBonPjBLYfTuONHzZSMT6ae66r6nQkEfGAixa8MaaYtfZQfoQREWc82KYa2w+d5JVv11O+aBS3NijjdCQRuUJ52UU/3xgz3RhzszFG17+LBCBjDC93qU+TikV4ePpyFm8/7HQkEblCeSn46sBYoA+w0RjzojGmundjiUh+Cw8JZmyfJMoWjmTw5MVsP3TS6UgicgXyMha9tdbOstb2wDVNbF9goTHmZ2NMC68nFJF8UyQ6jAn9mpBtLf0nLeJo2hmnI4nIZbpowRtjihljHjDGJAOP4LoGPh54GHjfy/lEJJ9Vio9mbJ8kUg6fYui7izmTqdnnRPxRXnbRzwMKAbdbaztYaz+x1mZaa5OB0d6NJyJOaFqpKC93qc+CrYd5/JMVunxOxA/l5TK5GtZaa4wpZIyJtdamnn3CWvtvL2YTEQfd3rAs2w+l8dr3G6hYLJr7b6jmdCQRuQR52YJvbIxZCawAVhljlhtjGns5l4j4gPtvqEqnhmV5ddYGPlu2y+k4InIJ8rIFPwEYbq39FcAYcxUwEajvzWAi4jxjDP/qXI9dR0/x6PQVlCkcSZOKRZ2OJSJ5kJct+Kyz5Q5grZ0DZHovkoj4kvCQYMb0aUxCkUiGTE5m60FdPifiD/JS8D8bY8YYY1obY641xrwF/GSMaWSMaeTtgCLivMJRrsvnAAZMWsSRk7p8TsTXXXQ2OWPM7As8ba2113s20uXRbHIi3pe87TA9xy0gsVxh3h3UlPCQYKcjiRRoF5pN7qLH4K2113k+koj4o6SKRXmla30emLaMxz9eyat3NkAjWIv4prxMNhMHPAtc4170M/C8tfaYN4OJiG/qmFiWnYfT+M93G6hQLIq/tdHI1SK+KC/H4CcAqcCd7ttxXGfRi0gBdc91VencKIHXv9/Ip0tTnI4jIrnIy2VyVay1nXM8fs4Ys8xLeUTEDxhj+Feneuw6msZjH62gZKEIWlaJdzqWiOSQly34U+5r3wEwxrQCTnkvkoj4g7CQIMb0TqJisWgGv5PM8p1HnY4kIjnkpeCHASONMduMMduAEcBQr6YSEb8QFxXKuwObUTQmjL4TF7JhX+rF3yQi+eKCBW+MCQb6WGsb4Bq5rr61tqG1dkW+pBMRn1cqLoL3BjYnLDiI3uMXsONQmtORRISLFLy1Ngu4yn3/uLX2eL6kEhG/Ur5YFO8ObMaZrGx6vT2ffcfTnY4kUuDlZRf9UmPMTGNMH2NMp7M3rycTEb9So1Qsk/o35fCJM/R5e4FGuxNxWF4KPgI4BFwP3Oq+3eLNUCLinxLLFWZc3yS2HUqj38SFnDitaStEnJKXgh9vre2f8wa8nZeVG2PaGWPWG2M2GWMez+X58saY2caYpcaYFcaYm93LKxpjThljlrlvoy/ta4mIU1pWiWdkz0as2n2cQe8sIj0jy+lIIgVSXgr+zTwu+wP3CXojgfZAbaCHMab2n172NPChtbYh0B14K8dzm621ie7bsDzkFBEfcWPtkvy3awMWbD3Mve8vISMr2+lIIgXOeQe6Mca0AFoCxY0xD+V4qhCQlxkmmgKbrLVb3OubBnQE1uR4jXWvDyAO2J336CLiy25vWJbU9Aye+Ww1j05fzqt3JhIUpHHrRfLLhUayCwNi3K+JzbH8ONAlD+suC+zM8TgFaPan1/wD+M4Ycx8QDbTJ8VwlY8xS9+c9nXNOehHxD31aVOR4eiavfLue2IhQnu9YR5PTiOST8xa8tfZnXHPBT7LWbvfS5/cAJllr/+veY/CuMaYusAcob609ZIxpDMwwxtT582V6xpghwBCA8uXLeymiiFyJ4a2rcPxUBmN+2UKhyBAebVvT6UgiBUJexqIPN8aMBSrmfH0e5oHfBZTL8TjBvSyngUA79/rmGWMigHhr7X7gtHv5YmPMZqA68IcJ3621Y4Gx4JoPPg/fRUTymTGGx9vX5Hh6BiNnb6ZQRChDr63idCyRgJeXgp8OjAbGA5dyOuwioJoxphKuYu8O9PzTa3YANwCTjDG1cF2Sd8AYUxw4bK3NMsZUBqoBWy7hs0XEhxhj+Oft9UhNz+RfX6+jUGQoPZpqr5uIN+Wl4DOttaMudcXW2kxjzL3At7hOyptgrV1tjHkeSLbWzgQeBsYZYx7EdcJdP2utNcZcAzxvjMkAsoFh1trDl5pBRHxHcJDh1TsTOXk6kyc/XUlMeAi3NijjdCyRgGWsvfCebWPMP4D9wKe4d5sD+FrhJiUl2eTk5Iu/UEQcdepMFn0nLGTJjiOMuyuJ62qWcDqSiN8yxiy21ibl9lxeroPvCzwK/AYsdt/UpCJyWSLDghnfL4mapWMZNmUxC7YccjqSSEC6aMFbayvlcqucH+FEJDAVigjlnf5NSSgSycB3klmZcszpSCIB57wFb4x5LMf9rn967kVvhhKRwFcsJpwpg5oRFxlK34kL2bRfc8mLeNKFtuC757j/xJ+ea+eFLCJSwJSOi+S9Qc0IMobe4xey87DmkhfxlAsVvDnP/dwei4hclorx0bw7sClpZzLp/fYC9msueRGPuFDB2/Pcz+2xiMhlq1W6EJMGNOVA6mnumrCQo2maS17kSl2o4BsYY44bY1KB+u77Zx/Xy6d8IlJANCpfhLF9kthy4CT9Jy3ipOaSF7ki5y14a22wtbaQtTbWWhvivn/2cWh+hhSRguGqavG80aMhK1KOMeTdZM0lL3IF8nIdvIhIvmlXtxQvd67P3E2HuH/qUjI1l7zIZVHBi4jP6dw4gWdvrc13a/bx2McryM7WaT8ilyovY9GLiOS7/q0qkZqeyauzNlAoIpRnb62tueRFLoEKXkR81n3XV+X4qQzGz9lKochQHrqxutORRPyGCl5EfJYxhqc61CI1PZM3fthIoYgQBl2tkbJF8kIFLyI+zRjDi53qkXo6g39+uZbYiBC6NdFc8iIXo4IXEZ8XHGR4rVsiJ04v5olPVhIbEcrN9Uo7HUvEp+ksehHxC+EhwYzu3YhG5YvwwLSlzF6/3+lIIj5NBS8ifiMqLIS3+zWhRqlYhr67mF82HHA6kojPUsGLiF+Jiwzl3QHNqFI8hsGTk5mz8aDTkUR8kgpeRPxOkegw3hvUjErx0QyavIjfNqvkRf5MBS8ifqmou+TLF41i4KRkFmw55HQkEZ+ighcRv1UsJpz3BjWnTOEI+k9aRPK2w05HEvEZKngR8WvFY8OZOrg5pQpF0HfCQhZvP+J0JBGfoIIXEb9XolAE7w9uTvHYcPpNWMiynUedjiTiOBW8iASEUnERTB3SnCLRYfR5ewErU445HUnEUSp4EQkYpeMimTqkOXGRofR+ewGrdqnkpeBSwYtIQClbOJKpg5sTEx5C77cXsGb3cacjiThCBS8iAadc0SimDm5OZGgwvcbPZ91elbwUPCp4EQlI5Yu5Sj4sJIhe4xawcV+q05FE8pUKXkQCVsX4aKYObk5QkKHHuAVs2n/C6Ugi+UYFLyIBrXLxGKYObg5Az3Hz2XJAJS8FgwpeRAJe1RIxvD+4GVnZlh7j5rPt4EmnI4l4nQpeRAqE6iVjeW9wM85kZtNj3Hx2HEpzOpKIV6ngRaTAqFmqEO8Nas6pjCx6jJvPzsMqeQlcKngRKVBqlynElIHNSE3PoOf4+ew6esrpSCJeoYIXkQKnbtk4pgxqxtG0DHqMnc+eYyp5CTwqeBEpkOonFObdgc04cvIMPcbOZ9/xdKcjiXiUCl5ECqzEcoWZNKApB1JP02PsfPar5CWAqOBFpEBrXKEIkwY0Ze/xdHqOX8CB1NNORxLxCBW8iBR4TSoWZWK/Juw6cope4+dz6IRKXvyfCl5EBGhWuRhv90tix+E0eo1fwOGTZ5yOJHJFVPAiIm4tq8Qz/q4mbD14kt7jF3A0TSUv/ksFLyKSw1XV4hl7VxKbDpyg99sLOJaW4XQkkcuighcR+ZNrqxdnTO/GbNh7grsmLODYKZW8+B8VvIhILq6rWYK3ejVizZ7j9J2wkNR0lbz4FxW8iMh5tKldkhE9G7Fq1zH6TVzEidOZTkcSyTMVvIjIBbStU4o3ezRk2c6j9NExefEjKngRkYtoX680o3o1YvWu4/QYp+vkxT+o4EVE8uCmOqUY1zeJLQdP0E1j14sfUMGLiOTRtdWL807/puw5eoquo+dpPnnxaSp4EZFL0KxyMfdUs2foNmYeWw6ccDqSSK5U8CIil6hh+SJMG9KC05nZ3DlmPuv3pjodSeQvVPAiIpehdplCfDC0OcFB0G3sPFamHHM6ksgfqOBFRC5T1RKxTB/akpjwEHqOm0/ytsNORxI5RwUvInIFyheL4sOhLSgeG06ftxcyd9NBpyOJACp4EZErVqZwJB8MbUH5olH0n7SIH9buczqSiApeRMQTiseGM21Ic2qWimXou4v5csUepyNJAaeCFxHxkCLRYUwZ1IyG5Qtz39QlfLQ4xelIUoCp4EVEPKhQRCjvDGhKyyrxPDJ9Oe/O2+Z0JCmgvFrwxph2xpj1xphNxpjHc3m+vDFmtjFmqTFmhTHm5hzPPeF+33pjTFtv5hQR8aSosBDG902iTa0SPPPZasb+stnpSFIAea3gjTHBwEigPVAb6GGMqf2nlz0NfGitbQh0B95yv7e2+3EdoB3wlnt9IiJ+ISI0mFG9G3NL/dK8+NU6Xpu1AWut07GkAAnx4rqbApustVsAjDHTgI7AmhyvsUAh9/04YLf7fkdgmrX2NLDVGLPJvb55XswrIuJRocFB/K97QyJCg/nfDxs5lZHFE+1rYoxxOpoUAN4s+LLAzhyPU4Bmf3rNP4DvjDH3AdFAmxzvnf+n95b1TkwREe8JDjK83Lk+UWHBjP1lC2lnMnn+troEBankxbu8WfB50QOYZK39rzGmBfCuMaZuXt9sjBkCDAEoX768lyKKiFyZoCDDc7fVITIsmDE/byHtTBYvd65PSLDOcxbv8WbB7wLK5Xic4F6W00Bcx9ix1s4zxkQA8Xl8L9bascBYgKSkJB3cEhGfZYzh8XY1iQ4L4dVZGzidkc1r3RIJC1HJi3d489+sRUA1Y0wlY0wYrpPmZv7pNTuAGwCMMbWACOCA+3XdjTHhxphKQDVgoRezioh4nTGG+2+oxtMdavHlyj0Mm7KY9Iwsp2NJgPJawVtrM4F7gW+BtbjOll9tjHneGHOb+2UPA4ONMcuBqUA/67Ia+BDXCXnfAPdYa/VfgYgEhEFXV+aFO+oye/1+BkxaxMnTmU5HkgBkAuWyjaSkJJucnOx0DBGRPPtkSQqPTF9Ow/JFmNi/CYUiQp2OJH7GGLPYWpuU23M6+CMi4pBOjRIY0bMRy3cepde4BRw5ecbpSBJAVPAiIg66uV5pxt7VmPX7Uuk+dj77U9OdjiQBQgUvIuKw62uWZFK/Juw8kka3MfPZffSU05EkAKjgRUR8QMuq8bw7sCkHU0/TdfQ8th866XQk8XMqeBERH9G4QlGmDmlO2plMuo6ex8Z9qU5HEj+mghcR8SF1y8YxbUgLLNBt7HxW7TrmdCTxUyp4EREfU6NULB8ObUFkaDDdx85n/pZDTkcSP6SCFxHxQZXio/no7haUiovgrgkLmbVmn9ORxM+o4EVEfFTpuEimD21BrdKFGDZlMdOTd178TSJuKngRER9WJDqM9wc1o0XlYjz60QrG/7rF6UjiJ1TwIiI+Ljo8hLf7JXFzvVL888u1vPzNOgJlmHHxHqfngxcRkTwIDwnmzR6NiItcxVs/beZI2hn+eXs9goOM09HER6ngRUT8RHCQ4cU76lI0OpSRszdz7FQGr3VLJDwk2Olo4oNU8CIifsQYw6Nta1IkKox/frmW46eSGdOnMdHh+t+5/JGOwYuI+KFBV1fmP10bMG/LIXqOX8BhzUQnf6KCFxHxU10aJzC6d2PW7jnOnWPmseeYJqmR36ngRUT82I21SzJ5QFP2HUuny6h5bD5wwulI4iNU8CIifq555WJMHdKc05lZdB09j5UpGr9eVPAiIgGhbtk4pg9r6R6/fh6/bT7odCRxmApeRCRAVIqP5uO7W1KmcCT9Jizim1V7nY4kDlLBi4gEkFJxEUwf1oLaZQox/L3FfLhI49cXVCp4EZEAUzgqjPcGNaNV1Xge+3gFY37e7HQkcYAKXkQkAEWHh/B23yZ0qF+af329jn99vVbj1xcwGvpIRCRAhYUE8Ub3hhSODGXMz1s4ejKDF+6oS0iwtu0KAhW8iEgACw4y/PP2uhSNDuPNHzdx7FQGr3dPJCJU49cHOv2MExEJcMYYHr6pBs/cUptvVu9lwKRFnDid6XQs8TIVvIhIATHwqkq8emcDFmw9TM9x8zl04rTTkcSLVPAiIgVIp0YJjOndmPV7U+k6Zh67jmr8+kClghcRKWDa1C7JuwObceD4abqM+o1N+1OdjiReoIIXESmAmlYqyrShzcnIsnQdPY/lO486HUk8TAUvIlJA1SkTx0fDWhAdHkLPcfOZu0nj1wcSFbyISAFW0T1+fUKRKPpPXMQ3q/Y4HUk8RAUvIlLAlSwUwQdDm1O3bCGGv7eEd+dvdzqSeIAKXkREKBwVxpRBzWhdowTPzFjFC1+uITtbQ9v6MxW8iIgAEBUWwtg+jbmrRQXG/bqV4e8t4dSZLKdjyWVSwYuIyDkhwUE8d1sdnu5Qi2/X7KXHuPkc1IA4fkkFLyIif2CMYdDVlRnVqzHr9h7njrfmsmn/CadjySVSwYuISK7a1S3FtCEtOHUmi05vzWX+lkNOR5JLoIIXEZHzSixXmE+Ht6JEoQj6vL2AT5akOB1J8kgFLyIiF1SuaBQfD2tJUoWiPPThcl7/fgPW6gx7X6eCFxGRi4qLCuWdAU3p1Kgsr3+/kYenL+dMZrbTseQCQpwOICIi/iEsJIj/dm1AhaLRvPb9BvYcTWd078bERYU6HU1yoS14ERHJM2MMD7Spxqt3NiB5+2E6jZrLzsNpTseSXKjgRUTkknVqlMDkAc04kHqaO96ayzLNRudzVPAiInJZWlQpxifDWxIZFkz3sfP4ZtVepyNJDip4ERG5bFVLxPLp8FbULFWIu99bzPhft+gMex+hghcRkSsSHxPOtCHNaVenFP/8ci3PzlxNZpbOsHeaCl5ERK5YRGgwI3s2Ysg1lZk8bztD3l3MydOZTscq0FTwIiLiEUFBhidvrsX/u70uP63fz51j5rHveLrTsQosFbyIiHhUn+YVeLtvE7YePMntI+eybu9xpyMVSCp4ERHxuOtqluDDoS3ItpYuo+bxy4YDTkcqcFTwIiLiFXXLxjHjnlYkFImk/6RFTF24w+lIBYoKXkREvKZ0XCTTh7WgVdV4nvhkJf/+Zh3Z2bqMLj+o4EVExKtiI0J5u28SPZqWZ9RPm7l/2lLSM7KcjhXwNNmMiIh4XWhwEC/eUZeKxaL419fr2HMsnXF3JVE0OszpaAFLW/AiIpIvjDEMvbYKI3s2YuWuY3R6ay5bD550OlbAUsGLiEi+6lC/NFMHN+N4eiZ3vDWXRdsOOx0pIKngRUQk3zWuUJRPh7ekaFQYvcYt4LNlu5yOFHC8WvDGmHbGmPXGmE3GmMdzef41Y8wy922DMeZojueycjw305s5RUQk/1UoFs3Hd7cksXxhHpi2jNdmbdBENR7ktZPsjDHBwEjgRiAFWGSMmWmtXXP2NdbaB3O8/j6gYY5VnLLWJnorn4iIOK9IdBhTBjbjyU9X8r8fNrLl4Ele6VKfiNBgp6P5PW9uwTcFNllrt1hrzwDTgI4XeH0PYKoX84iIiA8KCwnilS71eaxdDT5fvpse4+ZzIPW007H8njcLviywM8fjFPeyvzDGVAAqAT/mWBxhjEk2xsw3xtx+nvcNcb8m+cABDYMoIuKvjDEMb12V0b0bsXbPcW4fOZf1e1OdjuXXfOUku+7AR9banCMfVLDWJgE9gdeNMVX+/CZr7VhrbZK1Nql48eL5lVVERLykXd3SfDi0BRlZ2XQe9Ruz1+93OpLf8mbB7wLK5Xic4F6Wm+78afe8tXaX+88twE/88fi8iIgEqPoJhfns3laULxrFwEmLmDR3q9OR/JI3C34RUM0YU8kYE4arxP9yNrwxpiZQBJiXY1kRY0y4+3480ApY8+f3iohIYDo7hv31NUvyj8/X8PfPVpGZle10LL/itYK31mYC9wLfAmuBD621q40xzxtjbsvx0u7ANPvHayNqAcnGmOXAbOClnGffi4hI4IsOD2FMn8YMuaYyk+dtZ8A7yRxPz3A6lt8wgXLNYVJSkk1OTnY6hoiIeMG0hTt4esYqKsVHM6FfE8oVjXI6kk8wxix2n6/2F75ykp2IiMh5dW9anskDmrLveDq3j5zL4u0a3vZiVPAiIuIXWlaN59N7WhETEUIPDW97USp4ERHxG1WKxzBjeCsSy2l424tRwYuIiF85O7xtl8YJ/O+Hjdw/bRnpGVkXf2MB47Wx6EVERLzl7PC2lYtH8/I360k5ksbYPkkUjw13OprP0Ba8iIj4JQ1ve2EqeBER8Wsa3jZ3KngREfF7Gt72r1TwIiISEDS87R+p4EVEJGBoeNvfqeBFRCSgBAcZnry5Fi91qsdvmw7S+a3f2Hk4zelY+U4FLyIiAamgD2+rghcRkYBVkIe3VcGLiEhAK6jD26rgRUQk4BXE4W01VK2IiBQIZ4e3rVI8hn9/s44dh04ypk8SpeIinI7mFdqCFxGRAsMYw92tqzC2T2M27T/BrSPmsGTHEadjeYUKXkRECpyb6pTik+GtiAwNpvuY+UxP3ul0JI9TwYuISIFUo1Qsn93TiiaVivDoRyt47vPVATXynQpeREQKrCLRYbzTvyn9W1Vk4txt9Ju4iKNpZ5yO5REqeBERKdBCgoN49tY6vNylPgu3HqbjyLls2Of/086q4EVERIA7k8oxdUhzTp7O4o6Rc5m1Zp/Tka6ICl5ERMStcYUifH5fKyoXj2HIu8mM+HGj3w6Ko4IXERHJ4ey0s7c1KMN/vtvAve8vJe1MptOxLpkKXkRE5E8iQoN5vVsiT7SvyVer9tBl1DxSjvjXjHQqeBERkVwYYxh6bRUm9GvCziNpdBwxlwVbDjkdK89U8CIiIhdwXY0SzLinFXGRofQav4Ap87c7HSlPVPAiIiIXUaV4DJ/e04qrqsXz9IxVPD1jJRk+PiiOCl5ERCQP4iJDebtvE4ZeW5kp83fQa/wCDp047XSs81LBi4iI5FFwkOGJ9rV4vVsiy3ce5bYRc1mz+7jTsXKlghcREblEtzcsy/RhLcjKtnQe9RtfrdzjdKS/UMGLiIhchvoJhZl5bytqlY5l+HtLePW79WRn+86gOCp4ERGRy1SiUARThzTnzqQE3vhxE0OnLObEad8YFEcFLyIicgXCQ4L5d+f6PHtrbX5ct59Ob81l+6GTTsdSwYuIiFwpYwz9W1Vi8oCm7Dt+mttGzGXupoOOZlLBi4iIeEirqvHMvLcVJQuFc9eEhUycu9WxyWpU8CIiIh5UoVg0nwxvxfU1S/Dc52v4v49XcDozK99zqOBFREQ8LCY8hDG9G3P/DdX4MDmFHmPnsz81PV8zqOBFRES8ICjI8NCN1XmrVyPW7knltjfnsjLlWP59fr59koiISAF0c73SfHR3C2IjQgjKx9YNyb+PEhERKZjqlInjm79dQ3CQybfP1Ba8iIhIPsjPcgcVvIiISEBSwYuIiAQgFbyIiEgAUsGLiIgEIBW8iIhIAFLBi4iIBCAVvIiISABSwYuIiAQgFbyIiEgAUsGLiIgEIBW8iIhIAFLBi4iIBCAVvIiISABSwYuIiAQgFbyIiEgAUsGLiIgEIBW8iIhIADLWWqczeIQx5gCw3ekcHhAPHHQ6RD7Q9wws+p6BRd/Tf1Sw1hbP7YmAKfhAYYxJttYmOZ3D2/Q9A4u+Z2DR9wwM2kUvIiISgFTwIiIiAUgF73vGOh0gn+h7BhZ9z8Ci7xkAdAxeREQkAGkLXkREJACp4H2AMaacMWa2MWaNMWa1MeYBpzN5kzEm2Biz1BjzhdNZvMUYU9gY85ExZp0xZq0xpoXTmbzBGPOg+9/ZVcaYqcaYCKczeYIxZoIxZr8xZlWOZUWNMbOMMRvdfxZxMqMnnOd7vuL+93aFMeZTY0xhByN6RG7fM8dzDxtjrDEm3ols3qSC9w2ZwMPW2tpAc+AeY0xthzN50wPAWqdDeNn/gG+stTWBBgTg9zXGlAXuB5KstXWBYKC7s6k8ZhLQ7k/LHgd+sNZWA35wP/Z3k/jr95wF1LXW1gc2AE/kdygvmMRfvyfGmHLATcCO/A6UH1TwPsBau8dau8R9PxVXGZR1NpV3GGMSgA7AeKezeIsxJg64BngbwFp7xlp71NFQ3hMCRBpjQoAoYLfDeTzCWvsLcPhPizsC77jvvwPcnp+ZvCG372mt/c5am+l+OB9IyPdgHnaef54ArwGPAQF5MpoK3scYYyoCDYEFDkfxltdx/QeV7XAOb6oEHAAmug9FjDfGRDsdytOstbuA/+Da+tkDHLPWfudsKq8qaa3d476/FyjpZJh8MgD42ukQ3mCM6QjsstYudzqLt6jgfYgxJgb4GPibtfa403k8zRhzC7DfWrvY6SxeFgI0AkZZaxsCJwmM3bl/4D4G3RHXD5oyQLQxprezqfKHdV1+FJBbfWcZY57CdfjwPaezeJoxJgp4Evi701m8SQXvI4wxobjK/T1r7SdO5/GSVsBtxphtwDTgemPMFGcjeUUKkGKtPbsX5iNchR9o2gBbrbUHrLUZwCdAS4czedM+Y0xpAPef+x3O4zXGmH7ALUAvG5jXUlfB9cN0ufv/RwnAEmNMKUdTeZgK3gcYYwyu47VrrbWvOp3HW6y1T1hrE6y1FXGdjPWjtTbgtvistXuBncaYGu5FNwBrHIzkLTuA5saYKPe/wzcQgCcT5jAT6Ou+3xf4zMEsXmOMaYfrMNpt1to0p/N4g7V2pbW2hLW2ovv/RylAI/d/uwFDBe8bWgF9cG3RLnPfbnY6lFyR+4D3jDErgETgRWfjeJ57D8VHwBJgJa7/nwTEyGDGmKnAPKCGMSbFGDMQeAm40RizEdfei5eczOgJ5/meI4BYYJb7/0WjHQ3pAef5ngFPI9mJiIgEIG3Bi4iIBCAVvIiISABSwYuIiAQgFbyIiEgAUsGLiIgEIBW8iABgjMnKcZnmMmOMx0bfM8ZUzG0mLxHxnhCnA4iIzzhlrU10OoSIeIa24EXkgowx24wxLxtjVhpjFhpjqrqXVzTG/OieN/wHY0x59/KS7nnEl7tvZ4evDTbGjHPPH/+dMSbSsS8lUgCo4EXkrMg/7aLvluO5Y9baerhGOXvdvexN4B33vOHvAW+4l78B/GytbYBrDP7V7uXVgJHW2jrAUaCzV7+NSAGnkexEBABjzAlrbUwuy7cB11trt7gnRdprrS1mjDkIlLbWZriX77HWxhtjDgAJ1trTOdZREZhlra3mfvx/QKi19p/58NVECiRtwYtIXtjz3L8Up3Pcz0LnAIl4lQpeRPKiW44/57nv/4ZrVkCAXsCv7vs/AHcDGGOCjTFx+RVSRH6nX9AiclakMWZZjsffWGvPXipXxD0z3mmgh3vZfcBEY8yjwAGgv3v5A8BY94xdWbjKfo+3w4vIH+kYvIhckPsYfJK19qDTWUQk77SLXkREJABpC15ERCQAaQteREQkAKngRUREApAKXkREJACp4EVERAKQCl5ERCQAqeBFREQC0P8HBgitM89RZ3MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8, 8))\n",
    "ax.plot(np.arange(1,16), epoch_train_losses, label='Training')\n",
    "ax.plot(np.arange(1,16), epoch_dev_losses, label='Development')\n",
    "ax.legend(loc='best')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Entropy Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d655f07b-c687-4d9b-a0b3-44f0d3ccbead",
   "metadata": {},
   "source": [
    "The code below obtains predictions from our neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf4368a8-57fc-4cd3-b74e-aa385105c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nn(trained_model, test_loader):\n",
    "\n",
    "    trained_model.eval()  # switch off some randomisation used during training (dropout) to give consistent predictions\n",
    "\n",
    "    correct = 0  # count the number of correct classification labels\n",
    "\n",
    "    gold_labs = []  # gold labels to return\n",
    "    pred_labs = []  # predicted labels to return\n",
    "    \n",
    "    for inputs, labels in test_loader:\n",
    "        test_output = trained_model(inputs)  # run the forward() function on the inputs\n",
    "        predicted_labels = test_output.argmax(1)  # select the class labels with highest logits as our predictions\n",
    "\n",
    "        gold_labs.extend(labels.tolist())\n",
    "        pred_labs.extend(predicted_labels.tolist())\n",
    "    \n",
    "    return gold_labs, pred_labs\n",
    "\n",
    "gold_labs_1, pred_labs_1 = predict_nn(ff_classifier_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5620658-9e5a-4248-aa48-3e3868011aaf",
   "metadata": {},
   "source": [
    "Now, we can use pretrained word embeddings instead of learning them from scratch during training.\n",
    "Here, we will use the pretrained GloVe embeddings that we loaded before. The embedding matrix is used to initialise the embedding layer. The code below converts the GloVe embeddings into an embedding matrix suitable for PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "872638e9-f86c-48e4-8745-9c667e250a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Morg\\AppData\\Local\\Temp\\ipykernel_32888\\225966899.py:5: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  embedding_matrix[word_idx, :] = torch.from_numpy(glove_wv[word])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.3535,  0.0987,  0.1718,  ...,  0.4630,  1.3101,  1.1314],\n",
      "        [-0.4106,  0.1487,  0.0637,  ...,  0.6097,  1.0935,  0.9614],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = torch.zeros((vocab_size, glove_wv.vector_size))\n",
    "for word in vocab:\n",
    "    word_idx = vocab[word]\n",
    "    if word in glove_wv:\n",
    "        embedding_matrix[word_idx, :] = torch.from_numpy(glove_wv[word])\n",
    "        \n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e7656-343f-449c-9329-411ad7fb22d5",
   "metadata": {},
   "source": [
    "The class below extends the FFTextClassifier class (it's incomplete for now -- you'll fix this in a minute!). This means that it inherits all of its functionality, but we overwrite the constructor (the `__init__` method). This way, we don't need to define the forward function again, as it will be the same as before.\n",
    "\n",
    "The embedding layer is now different as it loads pretrained embeddings from our matrix. The argument `freeze` determines whether the embeddings remain fixed to their pretrained values (if `freeze=True`) or are updated through backpropagation to fit them to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09b93f97-57b9-4d3b-a36f-547d472e1f37",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FFTextClassifierWithEmbeddings(FFTextClassifier):\n",
    "\n",
    "    def __init__(self, hidden_size, sequence_length, num_classes, embedding_matrix):\n",
    "        super(FFTextClassifier, self).__init__()\n",
    "\n",
    "        self.embedding_size = embedding_matrix.shape[1] \n",
    "\n",
    "        # Here we just need to construct the components of our network. We don't need to connect them together yet.\n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(embedding_matrix, freeze=True) # embedding layer\n",
    "\n",
    "        self.hidden_layer = nn.Linear(self.embedding_size * sequence_length, hidden_size) # Hidden layer\n",
    "        self.activation = nn.ReLU() # Hidden layer activation\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes) # Fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae91af-4e37-476d-ba7d-709924bb329c",
   "metadata": {},
   "source": [
    "**TO-DO 2e:** Complete the arguments in the `FFTextClassifierWithEmbeddings` constructor to set the dimensions of the neural network layers.  Repeat the experiment above using the FFTextClassifierWithEmbeddings with the GLoVe embeddings. Choose a suitable performance metric and compare the performance of the two neural text classifiers. Explain in one or two sentences the possible reason(s) for any performance differences you observe. **(3 marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca4dbec",
   "metadata": {},
   "source": [
    "**ANSWER:** Accuracy on both the training and validation sets is lower for the text classifier with fixed embeddings. Furthermore, accuracy on the validation set using the embeddings does not improve from epoch 1-15. This implies that, in this case, fine-tuning the word embeddings by not freezing the embedding layer achieves better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73d4afd4-a92d-468d-a6ea-e693c10de36d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15 Training Loss: 1.0078 Training Accuracy: 45.8753%\n",
      "Epoch: 1/15 Validation Loss: 0.9987 Validation Accuracy: 46.3000%\n",
      "Epoch: 2/15 Training Loss: 0.9780 Training Accuracy: 48.9313%\n",
      "Epoch: 2/15 Validation Loss: 0.9981 Validation Accuracy: 47.3000%\n",
      "Epoch: 3/15 Training Loss: 0.9657 Training Accuracy: 49.8981%\n",
      "Epoch: 3/15 Validation Loss: 0.9915 Validation Accuracy: 48.0000%\n",
      "Epoch: 4/15 Training Loss: 0.9568 Training Accuracy: 50.5733%\n",
      "Epoch: 4/15 Validation Loss: 0.9951 Validation Accuracy: 47.2000%\n",
      "Epoch: 5/15 Training Loss: 0.9494 Training Accuracy: 51.2200%\n",
      "Epoch: 5/15 Validation Loss: 0.9966 Validation Accuracy: 47.4000%\n",
      "Epoch: 6/15 Training Loss: 0.9426 Training Accuracy: 51.8294%\n",
      "Epoch: 6/15 Validation Loss: 1.0044 Validation Accuracy: 46.9000%\n",
      "Epoch: 7/15 Training Loss: 0.9372 Training Accuracy: 52.2043%\n",
      "Epoch: 7/15 Validation Loss: 1.0049 Validation Accuracy: 47.6000%\n",
      "Epoch: 8/15 Training Loss: 0.9321 Training Accuracy: 52.5354%\n",
      "Epoch: 8/15 Validation Loss: 1.0167 Validation Accuracy: 47.0000%\n",
      "Epoch: 9/15 Training Loss: 0.9282 Training Accuracy: 52.9497%\n",
      "Epoch: 9/15 Validation Loss: 1.0112 Validation Accuracy: 46.7000%\n",
      "Epoch: 10/15 Training Loss: 0.9239 Training Accuracy: 53.1777%\n",
      "Epoch: 10/15 Validation Loss: 1.0165 Validation Accuracy: 46.9500%\n",
      "Epoch: 11/15 Training Loss: 0.9207 Training Accuracy: 53.5504%\n",
      "Epoch: 11/15 Validation Loss: 1.0218 Validation Accuracy: 47.2000%\n",
      "Epoch: 12/15 Training Loss: 0.9172 Training Accuracy: 53.7104%\n",
      "Epoch: 12/15 Validation Loss: 1.0236 Validation Accuracy: 46.4000%\n",
      "Epoch: 13/15 Training Loss: 0.9147 Training Accuracy: 54.1686%\n",
      "Epoch: 13/15 Validation Loss: 1.0312 Validation Accuracy: 46.0500%\n",
      "Epoch: 14/15 Training Loss: 0.9121 Training Accuracy: 54.2015%\n",
      "Epoch: 14/15 Validation Loss: 1.0323 Validation Accuracy: 46.3500%\n",
      "Epoch: 15/15 Training Loss: 0.9101 Training Accuracy: 54.4360%\n",
      "Epoch: 15/15 Validation Loss: 1.0327 Validation Accuracy: 46.4000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FFTextClassifierWithEmbeddings(\n",
       "  (embedding_layer): Embedding(43359, 25)\n",
       "  (hidden_layer): Linear(in_features=1000, out_features=8, bias=True)\n",
       "  (activation): ReLU()\n",
       "  (output_layer): Linear(in_features=8, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_clf_model_with_embeddings = FFTextClassifierWithEmbeddings(hidden_size, 40, num_classes, embedding_matrix)  # instatiate model\n",
    "train_nn(15, ff_clf_model_with_embeddings, train_loader, dev_loader)  # train model and evaluate on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df35d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_labs_2, pred_labs_2 = predict_nn(ff_clf_model_with_embeddings, test_loader)  # make predictions on test set and store for model evaluation later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c20d5-12c8-4820-89e2-e53c11b77b42",
   "metadata": {},
   "source": [
    "# 3. Improving the Neural Text Classifier (max. 22 marks)\n",
    "\n",
    "This section allows you some more free reign to experiment with the neural text classifier. Below, we list several to-dos that you can solve in your own way. Please make sure to label your notebook cells clearly so that it is obvious which to-do each cell corresponds to.\n",
    "\n",
    "**TO-DO 3a:** Consider the neural text classifiers we have just implemented and the results you obtained in the last to-do. The classifiers have a number of limitations that we could improve. Describe three limitations and how you could improve them. For each improvement you propose, provide a brief explanation (up to 1 paragraph) of how it works. \n",
    "\n",
    "Hint: refer to the lectures for some ideas. **(9 marks)**\n",
    "\n",
    "**3a ANSWER:**\n",
    "\n",
    "It is clear from to-do 2E that performance can be improved using fine-tuning. Fine-tuning backpropagates the loss to the word embeddings, adapting embeddings to this specific sentiment classification task. The training set contains 45,615 tweets and so is sufficiently large that fine-tuning is less likely to cause the model to overfit the training set.\n",
    "\n",
    "As discussed above, the model begins to overfit after several epochs. Therefore, a weight decay argument should be added to regularise the weights by penalising the size of each weight based on the L2 norm. This will help improve generalisation of the model on unseen data. Furthermore, an early stop is implemented during training of 5 epochs. After testing model performance on the training and validation sets, this seems to be an optimal point for performance on the validation set.\n",
    "\n",
    "The feedforward network designed has fixed weights for each input node. Therefore, a phrase with the same words and sentiment will be processed differently depending on phrase and word position in the document. Recurrent Neural Networks (RNN) and Long-short term memory (LSTM) layers address this problem by incorporating the activation from the previous token to the activation function for the current token. Thus, both methods incorporate the syntactic structure of the document. Additionally, LSTM layers incorporate a memory cell and gates, which stores context across time steps and controls information the model uses for activation at the next time step. The output of the final hidden state represents the output for the whole sequence of tokens. Performance on the sentiment classification task might be improved by incorporating this syntactic information and an LSTM layer before the fully-connected feedforward layer. It was found through validation that it was optimal to add two bi-directional LSTM layers. The resulting output from both last hidden states of both layers is concatenated and fed to the feedforward layer.\n",
    "\n",
    "---\n",
    "\n",
    "**TO-DO 3b:** Implement your improvements and compute the performance of your method. Make sure to comment your code to show where each new step is implemented. Use the validation set for any tuning you decide to do. Present your results clearly. **(13 marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3869577",
   "metadata": {},
   "source": [
    "**3b ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90b2ac",
   "metadata": {},
   "source": [
    "First, we redefine the network architecture with the embedding layer unfrozen and the additional two bidirectional LSTM layers. Following that, the forward function is modified to reflect the architecture changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ad91344",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFTextClassifierWithImprovements(FFTextClassifier):\n",
    "\n",
    "    def __init__(self, hidden_size, sequence_length, num_classes, embedding_matrix):\n",
    "        super(FFTextClassifier, self).__init__()\n",
    "\n",
    "        self.embedding_size = embedding_matrix.shape[1]\n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)  # embedding layer unfrozen to allow fine-tuning\n",
    "        self.lstm = nn.LSTM(self.embedding_size * sequence_length, hidden_size, num_layers=2, bidirectional=True, batch_first=True)  # LSTM layer set up with 8 neurons in each hidden state. \n",
    "        self.ffwd_layer_1 = nn.Linear(hidden_size*4, hidden_size)  # Feedforward layer takes an input of size 8x4 (4 because there are 4 final hidden states in a two-layer bidirectional LSTM)\n",
    "        self.activation = nn.ReLU()  # ReLU function to make output from ffwd layer non-linear\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)  # map to class labels\n",
    "        \n",
    "    def forward (self, input_words):\n",
    "\n",
    "        embedded_words = self.embedding_layer(input_words)\n",
    "        embedded_words = embedded_words.reshape(embedded_words.shape[0], sequence_length*self.embedding_size)  # reshape to 1D vector of length sequence length * embedding size\n",
    "        lstm_out, (final_hidden_state, final_cell_state) = self.lstm(embedded_words.view(len(input_words), 1, -1))  # reshape for input to LSTM \n",
    "        final_fwd_bwd = torch.cat((final_hidden_state[0,:], final_hidden_state[1,:], final_hidden_state[2,:], final_hidden_state[3,:]), dim = 1)  # concatenating the 4 final hidden states to a 1D vector of length 32\n",
    "        ffwd_output_1 = self.ffwd_layer_1(final_fwd_bwd)  # input LSTM output to the ffwd layer of 32 nodes\n",
    "        z = self.activation(ffwd_output_1)  # run output through ReLU function\n",
    "        output = self.output_layer(z)  # feed activations to the output layer\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed359aa",
   "metadata": {},
   "source": [
    "The next block instantiates and trains the model with added weight decay. Optimal value for weight decay determined through testing on the validation set is 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4046c486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5 Training Loss: 1.0264 Training Accuracy: 44.3955%\n",
      "Epoch: 1/5 Validation Loss: 1.0060 Validation Accuracy: 42.8500%\n",
      "Epoch: 2/5 Training Loss: 0.9879 Training Accuracy: 46.2830%\n",
      "Epoch: 2/5 Validation Loss: 0.9853 Validation Accuracy: 46.1500%\n",
      "Epoch: 3/5 Training Loss: 0.9231 Training Accuracy: 53.4714%\n",
      "Epoch: 3/5 Validation Loss: 0.9058 Validation Accuracy: 55.5000%\n",
      "Epoch: 4/5 Training Loss: 0.8426 Training Accuracy: 58.9017%\n",
      "Epoch: 4/5 Validation Loss: 0.8732 Validation Accuracy: 56.2500%\n",
      "Epoch: 5/5 Training Loss: 0.7809 Training Accuracy: 63.0275%\n",
      "Epoch: 5/5 Validation Loss: 0.8049 Validation Accuracy: 62.5500%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FFTextClassifierWithImprovements(\n",
       "  (embedding_layer): Embedding(43359, 25)\n",
       "  (lstm): LSTM(1000, 8, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (ffwd_layer_1): Linear(in_features=32, out_features=8, bias=True)\n",
       "  (activation): ReLU()\n",
       "  (output_layer): Linear(in_features=8, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_clf_model_with_imp = FFTextClassifierWithImprovements(hidden_size, 40, num_classes, embedding_matrix)\n",
    "train_nn(5, ff_clf_model_with_imp, train_loader, dev_loader, weight_decay=1e-3)  # add weight_decay. Optimal from testing on validation set was 1e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "294de372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE ON THE TEST SET:\n",
      "\n",
      "ACCURACY: 0.572289156626506\n",
      "F1 SCORE: 0.5306477844339129\n",
      "\n",
      "\n",
      "Predict    0          1          2          \n",
      "Actual\n",
      "0          1144       2541       287        \n",
      "\n",
      "1          566        4625       746        \n",
      "\n",
      "2          63         1051       1261       \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pycm\n",
    "\n",
    "gold_labs_3, pred_labs_3 = predict_nn(ff_clf_model_with_imp, test_loader)  # make predictions on the test set\n",
    "cm = pycm.ConfusionMatrix(gold_labs_3, pred_labs_3)\n",
    "print(f'PERFORMANCE ON THE TEST SET:\\n\\nACCURACY: {accuracy_score(gold_labs_3, pred_labs_3)}\\nF1 SCORE: {f1_score(gold_labs_3, pred_labs_3, average=\"macro\")}\\n\\n')\n",
    "cm.print_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc22195",
   "metadata": {},
   "source": [
    "### Other models' performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de0d8e",
   "metadata": {},
   "source": [
    "To compare performance and see if our improvements worked, we will run our evaluation metrics on the other two classifiers in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e853d4b",
   "metadata": {},
   "source": [
    "#### Model with word2vec skipgram embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e92a188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE ON THE TEST SET:\n",
      "\n",
      "ACCURACY: 0.5018723542819928\n",
      "F1 SCORE: 0.43707177604215613\n",
      "\n",
      "\n",
      "Predict    0          1          2          \n",
      "Actual\n",
      "0          571        2718       683        \n",
      "\n",
      "1          372        4258       1307       \n",
      "\n",
      "2          81         958        1336       \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = pycm.ConfusionMatrix(gold_labs_1, pred_labs_1)\n",
    "print(f'PERFORMANCE ON THE TEST SET:\\n\\nACCURACY: {accuracy_score(gold_labs_1, pred_labs_1)}\\nF1 SCORE: {f1_score(gold_labs_1, pred_labs_1, average=\"macro\")}\\n\\n')\n",
    "cm.print_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c90ea24",
   "metadata": {},
   "source": [
    "#### Model with GLoVE embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3aec24e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE ON THE TEST SET:\n",
      "\n",
      "ACCURACY: 0.43633995441224355\n",
      "F1 SCORE: 0.3434437635586316\n",
      "\n",
      "\n",
      "Predict    0          1          2          \n",
      "Actual\n",
      "0          285        2858       829        \n",
      "\n",
      "1          170        4136       1631       \n",
      "\n",
      "2          49         1387       939        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = pycm.ConfusionMatrix(gold_labs_2, pred_labs_2)\n",
    "print(f'PERFORMANCE ON THE TEST SET:\\n\\nACCURACY: {accuracy_score(gold_labs_2, pred_labs_2)}\\nF1 SCORE: {f1_score(gold_labs_2, pred_labs_2, average=\"macro\")}\\n\\n')\n",
    "cm.print_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f620bd8d",
   "metadata": {},
   "source": [
    "Our LSTM model achieves the best performance on the test set with 57% accuracy and 53% F1 score, but still does not perform exceptionally well (>70% accuracy/F1) like some state-of-the-art models. Class imbalance is one issue here with poor recall for both classes 0 and 2. More performance could potentially be extracted using self-attentive layers and transformers. Furthermore techniques that tackle the class imbalance issue could be effective in improving performance, e.g. upsampling the minority classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
